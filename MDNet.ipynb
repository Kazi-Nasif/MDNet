{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "179be735",
   "metadata": {},
   "source": [
    "##### Import Libraries, Openmm must be intalled prior to this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99a4d3b3-b644-4df7-9a67-c2f244fdb26f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: importing 'simtk.openmm' is deprecated.  Import 'openmm' instead.\n",
      "/mnt/bst/bdeng2/knasif/miniconda3/envs/MDSim/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from simtk.openmm.app import *\n",
    "from simtk.openmm.app import *\n",
    "from simtk.openmm import *\n",
    "from simtk.unit import *\n",
    "import MDAnalysis as md\n",
    "import xdrlib\n",
    "import warnings\n",
    "import time\n",
    "from pdbfixer import PDBFixer\n",
    "from sys import stdout\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b63f32",
   "metadata": {},
   "source": [
    "##### Loading Raw PDB files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "f256063d-c68e-4630-a3d9-793ca5f1bb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdb0_file = 'data/villin_water.pdb'\n",
    "pdb1_file = 'data/polyALA.pdb'\n",
    "pdb2_file = 'data/polyGLY.pdb'\n",
    "pdb3_file = 'data/polyGV.pdb'\n",
    "pdb4_file = 'data/8xj3.pdb'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7b2b63",
   "metadata": {},
   "source": [
    "##### Fixing PDB files for missing residues and bonds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83528e12-0724-4724-894d-be5b8ca33594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PDBFixer...\n",
      "Finding missing residues...\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "Finding nonstandard residues...\n",
      "Replacing nonstandard residues...\n",
      "Removing heterogens...\n",
      "Finding missing atoms...\n",
      "Adding missing atoms...\n",
      "Adding missing hydrogens...\n",
      "Writing PDB file...\n",
      "Fixed PDB saved at /mnt/bst/bdeng2/knasif/MD/data/7dmu_fixed_pH_7.pdb\n"
     ]
    }
   ],
   "source": [
    "from pdbfixer import PDBFixer\n",
    "from simtk.openmm.app import PDBFile\n",
    "import os\n",
    "\n",
    "def fix_pdb(pdb_id):\n",
    "    path = os.getcwd()\n",
    "    if len(pdb_id) != 4:\n",
    "        print(\"Creating PDBFixer...\")\n",
    "        fixer = PDBFixer(filename=pdb_id)\n",
    "        print(\"Finding missing residues...\")\n",
    "        fixer.findMissingResidues()\n",
    "\n",
    "        chains = list(fixer.topology.chains())\n",
    "        keys = fixer.missingResidues.keys()\n",
    "        for key in list(keys):\n",
    "            chain = chains[key[0]]\n",
    "            if key[1] == 0 or key[1] == len(list(chain.residues())):\n",
    "                print(\"ok\")\n",
    "                del fixer.missingResidues[key]\n",
    "\n",
    "        print(\"Finding nonstandard residues...\")\n",
    "        fixer.findNonstandardResidues()\n",
    "        print(\"Replacing nonstandard residues...\")\n",
    "        fixer.replaceNonstandardResidues()\n",
    "        print(\"Removing heterogens...\")\n",
    "        fixer.removeHeterogens(keepWater=True)\n",
    "\n",
    "        print(\"Finding missing atoms...\")\n",
    "        fixer.findMissingAtoms()\n",
    "        print(\"Adding missing atoms...\")\n",
    "        fixer.addMissingAtoms()\n",
    "        print(\"Adding missing hydrogens...\")\n",
    "        fixer.addMissingHydrogens(7.0)\n",
    "        print(\"Writing PDB file...\")\n",
    "\n",
    "        fixed_pdb_file = os.path.join(path, \"%s_fixed_pH_%s.pdb\" % (pdb_id.split('.')[0], 7))\n",
    "        with open(fixed_pdb_file, \"w\") as outfile:\n",
    "            PDBFile.writeFile(\n",
    "                fixer.topology, \n",
    "                fixer.positions, \n",
    "                outfile, \n",
    "                keepIds=True\n",
    "            )\n",
    "        return fixed_pdb_file\n",
    "\n",
    "fixed_pdb = fix_pdb('data/7dmu.pdb')\n",
    "\n",
    "if fixed_pdb:\n",
    "    print(f\"Fixed PDB saved at {fixed_pdb}\")\n",
    "else:\n",
    "    print(\"PDB fixing failed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e85283a",
   "metadata": {},
   "source": [
    "##### MD Simulation and dataset creation, recommended to do in a separate .py file for larger simulation steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f409b59-33b3-496f-b54a-49d18f0338ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: importing 'simtk.openmm' is deprecated.  Import 'openmm' instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created\n"
     ]
    }
   ],
   "source": [
    "from simtk.openmm.app import *\n",
    "from simtk.openmm import *\n",
    "from simtk.unit import *\n",
    "import numpy as np\n",
    "\n",
    "# File paths\n",
    "pdb5_file = 'data/7dmu_fixed_pH_7.pdb'\n",
    "force_field_files = ['amber14-all.xml', 'amber14/tip3p.xml']\n",
    "\n",
    "# Load initial coordinates from a PDB file\n",
    "pdb = PDBFile(pdb5_file)\n",
    "\n",
    "# Choosing force field parameters\n",
    "ff = ForceField(*force_field_files)\n",
    "system = ff.createSystem(pdb.topology, nonbondedMethod=CutoffNonPeriodic)\n",
    "\n",
    "# Experiment parameters\n",
    "temperature = 300 * kelvin\n",
    "friction_coeff = 1 / picosecond\n",
    "time_step = 0.002 * picoseconds\n",
    "total_steps = 100000\n",
    "save_interval = 1000  # Interval at which to save the coordinates\n",
    "\n",
    "# Calculate how many data points will be saved\n",
    "num_data_points = total_steps // save_interval\n",
    "\n",
    "# Integrator\n",
    "integrator = LangevinIntegrator(temperature, friction_coeff, time_step)\n",
    "\n",
    "# Set a seed for Langevin integrator for reproducibility\n",
    "seed = 42\n",
    "integrator.setRandomNumberSeed(seed)\n",
    "\n",
    "# Create a simulation object\n",
    "simulation = Simulation(pdb.topology, system, integrator)\n",
    "simulation.context.setPositions(pdb.positions)\n",
    "simulation.minimizeEnergy()\n",
    "\n",
    "# Initialize an array to store the selected data points\n",
    "positions_array = np.zeros((num_data_points, pdb.topology.getNumAtoms(), 3))\n",
    "\n",
    "# Run the simulation and collect data at specified intervals\n",
    "data_index = 0\n",
    "for step in range(1, total_steps + 1):\n",
    "    simulation.step(1)\n",
    "    if step % save_interval == 0:\n",
    "        state = simulation.context.getState(getPositions=True)\n",
    "        positions_array[data_index] = state.getPositions(asNumpy=True).value_in_unit(nanometers)\n",
    "        data_index += 1\n",
    "\n",
    "# Initialize lists to store PDB information\n",
    "residue_numbers = []\n",
    "residue_names = []\n",
    "atom_names = []\n",
    "\n",
    "# Extract residue numbers, names, and atom names from the PDB file\n",
    "with open(pdb5_file, 'r') as pdb_file:\n",
    "    for line in pdb_file:\n",
    "        if line.startswith('ATOM'):\n",
    "            columns = line.split()\n",
    "            atom_names.append(columns[2])\n",
    "            residue_names.append(columns[3])\n",
    "            residue_numbers.append(int(columns[5]))\n",
    "\n",
    "# Determine the number of intervals (e.g., 1000th steps included)\n",
    "num_intervals = total_steps // save_interval\n",
    "\n",
    "# Define dtype for the structured array\n",
    "dtype = [\n",
    "    ('residue_number', 'i4'),\n",
    "    ('residue_name', 'U3'),\n",
    "    ('atom_name', 'U3'),\n",
    "    ('x', 'f4'),\n",
    "    ('y', 'f4'),\n",
    "    ('z', 'f4')\n",
    "]\n",
    "\n",
    "structured_array = np.zeros((num_intervals, pdb.topology.getNumAtoms()), dtype=dtype)\n",
    "\n",
    "# Fill the structured array with data from the selected positions and the PDB file\n",
    "for interval_index in range(num_intervals):\n",
    "    for atom_index in range(pdb.topology.getNumAtoms()):\n",
    "        structured_array[interval_index, atom_index] = (\n",
    "            residue_numbers[atom_index],\n",
    "            residue_names[atom_index],\n",
    "            atom_names[atom_index],\n",
    "            positions_array[interval_index, atom_index, 0],\n",
    "            positions_array[interval_index, atom_index, 1],\n",
    "            positions_array[interval_index, atom_index, 2]\n",
    "        )\n",
    "\n",
    "# Save the structured array with selected positions and PDB information\n",
    "np.save('data/7dmu_pos.npy', structured_array)\n",
    "\n",
    "print(\"Dataset created\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb42928",
   "metadata": {},
   "source": [
    "##### Loading saved positions from MD simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66538ac9-a4b4-4764-ae2f-a97b022680cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "positions=np.load('data/8sk7_pos_20ns.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85214a8a-99e0-4b9c-a031-e246837e590c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 26115)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b426ce7b-08af-41b1-9f0c-7f99a247166c",
   "metadata": {},
   "source": [
    "##### Extracting Alpha-Carbons, Alpha Carbons are the backbone of the protein structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8142deb3-3f4f-449e-95fa-75a3c16ec55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_pos=positions[positions['atom_name'] == 'CA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5223060-0089-4bf0-b544-96a725e41912",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data/8sk7_ca_pos.npy',ca_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a39d7ea-442e-49c0-86bd-db51249bc56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_positions=np.load('data/8sk7_ca_pos.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97d5f330-705e-48d1-895e-2ec4301258fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1653000,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ca_positions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ce0230",
   "metadata": {},
   "source": [
    "##### Reshaping Dataset in a 3D format (number of data points, number of residues, (x,y,z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c69f6abc-c106-4ed5-bda9-1b33038f33fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# last three columns, which correspond to the (x, y, z) coordinates\n",
    "atomic_coordinates = np.stack((ca_positions['x'], ca_positions['y'], ca_positions['z']), axis=-1)\n",
    "\n",
    "# Reshape the data for scaling: \n",
    "num_steps = 1000  # The number of data points in the dataset\n",
    "num_res = len(ca_positions) // num_steps\n",
    "atomic_coordinates = atomic_coordinates.reshape(num_steps,num_res, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f154408-2f0a-4188-a277-a57bf6079a08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1653, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atomic_coordinates.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17f22199-3371-4fbf-aee7-b3122109467b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /mnt/bst/bdeng2/knasif/miniconda3/envs/MDSim/lib/python3.8/site-packages (2.13.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /mnt/bst/bdeng2/knasif/miniconda3/envs/MDSim/lib/python3.8/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /mnt/bst/bdeng2/knasif/miniconda3/envs/MDSim/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in /mnt/bst/bdeng2/knasif/miniconda3/envs/MDSim/lib/python3.8/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /mnt/bst/bdeng2/knasif/miniconda3/envs/MDSim/lib/python3.8/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /mnt/bst/bdeng2/knasif/miniconda3/envs/MDSim/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /mnt/bst/bdeng2/knasif/miniconda3/envs/MDSim/lib/python3.8/site-packages (from tensorflow) (1.63.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /mnt/bst/bdeng2/knasif/.local/lib/python3.8/site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in /mnt/bst/bdeng2/knasif/miniconda3/envs/MDSim/lib/python3.8/site-packages (from tensorflow) (2.13.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /mnt/bst/bdeng2/knasif/miniconda3/envs/MDSim/lib/python3.8/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /mnt/bst/bdeng2/knasif/miniconda3/envs/MDSim/lib/python3.8/site-packages (from tensorflow) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /mnt/bst/bdeng2/knasif/miniconda3/envs/MDSim/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /mnt/bst/bdeng2/knasif/miniconda3/envs/MDSim/lib/python3.8/site-packages (from tensorflow) (24.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /mnt/bst/bdeng2/knasif/miniconda3/envs/MDSim/lib/python3.8/site-packages (from tensorflow) (4.25.3)\n",
      "Requirement already satisfied: setuptools in /mnt/bst/bdeng2/knasif/miniconda3/envs/MDSim/lib/python3.8/site-packages (from tensorflow) (69.5.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /mnt/bst/bdeng2/knasif/miniconda3/envs/MDSim/lib/python3.8/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in /mnt/bst/bdeng2/knasif/miniconda3/envs/MDSim/lib/python3.8/site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /mnt/bst/bdeng2/knasif/miniconda3/envs/MDSim/lib/python3.8/site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /mnt/bst/bdeng2/knasif/miniconda3/envs/MDSim/lib/python3.8/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /mnt/bst/bdeng2/knasif/miniconda3/envs/MDSim/lib/python3.8/site-packages (from tensorflow) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /mnt/bst/bdeng2/knasif/miniconda3/envs/MDSim/lib/python3.8/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /mnt/bst/bdeng2/knasif/miniconda3/envs/MDSim/lib/python3.8/site-packages (from tensorflow) (0.34.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /mnt/bst/bdeng2/knasif/miniconda3/envs/MDSim/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /mnt/bst/bdeng2/knasif/miniconda3/envs/MDSim/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.29.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /mnt/bst/bdeng2/knasif/miniconda3/envs/MDSim/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /mnt/bst/bdeng2/knasif/miniconda3/envs/MDSim/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /mnt/bst/bdeng2/knasif/miniconda3/envs/MDSim/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /mnt/bst/bdeng2/knasif/miniconda3/envs/MDSim/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /mnt/bst/bdeng2/knasif/miniconda3/envs/MDSim/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /mnt/bst/bdeng2/knasif/miniconda3/envs/MDSim/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /mnt/bst/bdeng2/knasif/miniconda3/envs/MDSim/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /mnt/bst/bdeng2/knasif/miniconda3/envs/MDSim/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /mnt/bst/bdeng2/knasif/miniconda3/envs/MDSim/lib/python3.8/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /mnt/bst/bdeng2/knasif/miniconda3/envs/MDSim/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow) (7.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /mnt/bst/bdeng2/knasif/miniconda3/envs/MDSim/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /mnt/bst/bdeng2/knasif/miniconda3/envs/MDSim/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /mnt/bst/bdeng2/knasif/miniconda3/envs/MDSim/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /mnt/bst/bdeng2/knasif/miniconda3/envs/MDSim/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /mnt/bst/bdeng2/knasif/miniconda3/envs/MDSim/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: zipp>=0.5 in /mnt/bst/bdeng2/knasif/.local/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow) (3.19.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /mnt/bst/bdeng2/knasif/miniconda3/envs/MDSim/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /mnt/bst/bdeng2/knasif/miniconda3/envs/MDSim/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6872d0",
   "metadata": {},
   "source": [
    "##### import necessary libraries for Machine Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "919c7a85-5158-4776-b022-5a770a53f1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Reshape\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6f4d090-e17b-425e-9894-050b40c706f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Reshape\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer, MultiHeadAttention, Input, Conv2D, MaxPooling2D, Flatten, Dense, Reshape, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, GlobalAveragePooling2D, Reshape, Input, Add, Activation, BatchNormalization, add"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e7e91f",
   "metadata": {},
   "source": [
    "##### Normalize and Reshape the dataset in a grid format to fit in CNN model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "65f552bd-acac-49ac-9466-dd97d86b6d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "scaler = StandardScaler()\n",
    "positions_normalized = scaler.fit_transform(atomic_coordinates.reshape(-1, atomic_coordinates.shape[-1])).reshape(atomic_coordinates.shape)\n",
    "\n",
    "# Calculate grid size based on the number of residues\n",
    "import math\n",
    "grid_size = int(math.ceil(math.sqrt(num_res)))\n",
    "\n",
    "# Reshape the data for Conv2D input\n",
    "reshaped_data = np.zeros((positions_normalized.shape[0], grid_size, grid_size, 3))  # Dynamically sized grid\n",
    "\n",
    "for i in range(positions_normalized.shape[0]):\n",
    "    for j in range(num_res):\n",
    "        row = j // grid_size\n",
    "        col = j % grid_size\n",
    "        reshaped_data[i, row, col, :] = positions_normalized[i, j, :]\n",
    "\n",
    "# Create input (X) and output (y) data for the model\n",
    "X = reshaped_data[:-1]\n",
    "y = reshaped_data[1:]\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1fd3b0",
   "metadata": {},
   "source": [
    "##### Attention Layer Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2530839d-05c4-4d44-87ce-4521c3b89fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(Layer):\n",
    "    def __init__(self, embed_dim, num_heads=8):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.attention = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Attention mechanism where the query, key, and value are the same\n",
    "        return self.attention(inputs, inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599f5f68",
   "metadata": {},
   "source": [
    "##### MDNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b5cde3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Mish activation function\n",
    "def mish(x):\n",
    "    return x * tf.math.tanh(tf.math.softplus(x))\n",
    "\n",
    "# Register Mish as a custom activation function\n",
    "tf.keras.utils.get_custom_objects().update({'mish': Activation(mish)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6ac09a08-680d-4df7-98dc-2a5fb7afe57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(num_res):\n",
    "    # Calculate grid size based on the number of atoms\n",
    "    grid_size = int(math.ceil(math.sqrt(num_res)))\n",
    "\n",
    "    # Build the Conv2D model with dynamic input shape\n",
    "    input_layer = Input(shape=(grid_size, grid_size, 3))\n",
    "    x = Conv2D(32, (3, 3), activation='mish', padding='same')(input_layer)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = SelfAttention(embed_dim=32)(x)\n",
    "    x = Conv2D(64, (3, 3), activation='mish', padding='same')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation='mish')(x)\n",
    "    x = Dense(grid_size * grid_size * 3)(x)\n",
    "    output_layer = Reshape((grid_size, grid_size, 3))(x)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    model.compile(optimizer='adam', loss='mean_absolute_error')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "37cf7107-2f62-45ab-b204-3b055f2f005c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 41, 41, 3)]       0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 41, 41, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 20, 20, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 20, 20, 32)        128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " self_attention_1 (SelfAtte  (None, 20, 20, 32)        33568     \n",
      " ntion)                                                          \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 20, 20, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 10, 10, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 10, 10, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 6400)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               819328    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 5043)              650547    \n",
      "                                                                 \n",
      " reshape_1 (Reshape)         (None, 41, 41, 3)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1523219 (5.81 MB)\n",
      "Trainable params: 1523027 (5.81 MB)\n",
      "Non-trainable params: 192 (768.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(num_res)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3489aa4b-f4c6-4fef-bced-33310d37fe37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "20/20 [==============================] - 3s 31ms/step - loss: 0.3556 - val_loss: 0.8122\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.1125 - val_loss: 0.8052\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.0791 - val_loss: 0.7995\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.0763 - val_loss: 0.7930\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.0568 - val_loss: 0.7912\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.0482 - val_loss: 0.7882\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.0536 - val_loss: 0.7853\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.0481 - val_loss: 0.7818\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.0583 - val_loss: 0.7763\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.0407 - val_loss: 0.7719\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.0426 - val_loss: 0.7664\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.0368 - val_loss: 0.7591\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.0353 - val_loss: 0.7490\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.0443 - val_loss: 0.7376\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.0410 - val_loss: 0.7216\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.0306 - val_loss: 0.7038\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.0369 - val_loss: 0.6903\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.0313 - val_loss: 0.6685\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.0271 - val_loss: 0.6514\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.0362 - val_loss: 0.6228\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.0336 - val_loss: 0.5877\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.0301 - val_loss: 0.5555\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.0274 - val_loss: 0.5236\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.0266 - val_loss: 0.4976\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.0264 - val_loss: 0.4624\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.0324 - val_loss: 0.4392\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.0409 - val_loss: 0.3936\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.0303 - val_loss: 0.3226\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.0252 - val_loss: 0.3011\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.0303 - val_loss: 0.2798\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.0267 - val_loss: 0.2298\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.0260 - val_loss: 0.1990\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.0273 - val_loss: 0.1731\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.0223 - val_loss: 0.1519\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.0220 - val_loss: 0.1385\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.0236 - val_loss: 0.1152\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.0229 - val_loss: 0.1053\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.0257 - val_loss: 0.0899\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.0238 - val_loss: 0.0673\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.0231 - val_loss: 0.0560\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.0222 - val_loss: 0.0503\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.0231 - val_loss: 0.0490\n",
      "Epoch 43/100\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.0258 - val_loss: 0.0344\n",
      "Epoch 44/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.0229 - val_loss: 0.0260\n",
      "Epoch 45/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.0237 - val_loss: 0.0251\n",
      "Epoch 46/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.0242 - val_loss: 0.0250\n",
      "Epoch 47/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.0225 - val_loss: 0.0264\n",
      "Epoch 48/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.0224 - val_loss: 0.0361\n",
      "Epoch 49/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.0256 - val_loss: 0.0242\n",
      "Epoch 50/100\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.0258 - val_loss: 0.0287\n",
      "Epoch 51/100\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.0228 - val_loss: 0.0210\n",
      "Epoch 52/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.0219 - val_loss: 0.0250\n",
      "Epoch 53/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.0213 - val_loss: 0.0214\n",
      "Epoch 54/100\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.0213 - val_loss: 0.0242\n",
      "Epoch 55/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.0227 - val_loss: 0.0248\n",
      "Epoch 56/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.0219 - val_loss: 0.0203\n",
      "Epoch 57/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.0206 - val_loss: 0.0212\n",
      "Epoch 58/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.0198 - val_loss: 0.0213\n",
      "Epoch 59/100\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.0201 - val_loss: 0.0234\n",
      "Epoch 60/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.0216 - val_loss: 0.0284\n",
      "Epoch 61/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.0207 - val_loss: 0.0262\n",
      "Epoch 62/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.0211 - val_loss: 0.0240\n",
      "Epoch 63/100\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.0203 - val_loss: 0.0211\n",
      "Epoch 64/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.0211 - val_loss: 0.0269\n",
      "Epoch 65/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.0224 - val_loss: 0.0261\n",
      "Epoch 66/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.0207 - val_loss: 0.0277\n",
      "Epoch 67/100\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.0207 - val_loss: 0.0219\n",
      "Epoch 68/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.0213 - val_loss: 0.0280\n",
      "Epoch 69/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.0198 - val_loss: 0.0221\n",
      "Epoch 70/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.0219 - val_loss: 0.0230\n",
      "Epoch 71/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.0228 - val_loss: 0.0257\n",
      "Epoch 72/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.0193 - val_loss: 0.0210\n",
      "Epoch 73/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.0203 - val_loss: 0.0256\n",
      "Epoch 74/100\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.0198 - val_loss: 0.0235\n",
      "Epoch 75/100\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.0198 - val_loss: 0.0244\n",
      "Epoch 76/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.0213 - val_loss: 0.0202\n",
      "Epoch 77/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.0198 - val_loss: 0.0214\n",
      "Epoch 78/100\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.0195 - val_loss: 0.0239\n",
      "Epoch 79/100\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.0195 - val_loss: 0.0240\n",
      "Epoch 80/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.0200 - val_loss: 0.0214\n",
      "Epoch 81/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.0188 - val_loss: 0.0212\n",
      "Epoch 82/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.0199 - val_loss: 0.0232\n",
      "Epoch 83/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.0206 - val_loss: 0.0220\n",
      "Epoch 84/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.0192 - val_loss: 0.0239\n",
      "Epoch 85/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.0194 - val_loss: 0.0230\n",
      "Epoch 86/100\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.0188 - val_loss: 0.0229\n",
      "Epoch 87/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.0191 - val_loss: 0.0251\n",
      "Epoch 88/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.0201 - val_loss: 0.0216\n",
      "Epoch 89/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.0192 - val_loss: 0.0244\n",
      "Epoch 90/100\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.0191 - val_loss: 0.0209\n",
      "Epoch 91/100\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.0192 - val_loss: 0.0203\n",
      "Epoch 92/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.0192 - val_loss: 0.0200\n",
      "Epoch 93/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.0192 - val_loss: 0.0237\n",
      "Epoch 94/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.0194 - val_loss: 0.0199\n",
      "Epoch 95/100\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.0197 - val_loss: 0.0231\n",
      "Epoch 96/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.0192 - val_loss: 0.0220\n",
      "Epoch 97/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.0185 - val_loss: 0.0192\n",
      "Epoch 98/100\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.0187 - val_loss: 0.0245\n",
      "Epoch 99/100\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.0197 - val_loss: 0.0222\n",
      "Epoch 100/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.0210 - val_loss: 0.0223\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fefcc167970>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=32, epochs=100, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7c94e7f9-871a-421a-8ed0-91d29737c019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0218\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.021833930164575577"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc41fd3-7ba0-4bc1-a323-dc7ced6ff875",
   "metadata": {},
   "source": [
    "#### Denormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "971be88e-e9cb-45e3-b425-d9d5b14e878e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 3ms/step\n",
      "Mean Absolute Error on Actual Data: 0.00414960981101557\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Grid dimensions based on the dataset\n",
    "grid_size = int(math.ceil(np.sqrt(num_res)))  # Assuming num_residues has been calculated as the nearest perfect square\n",
    "\n",
    "# Predict using the model on normalized test data\n",
    "predicted_normalized = model.predict(X_test)\n",
    "\n",
    "# Denormalize the predicted data\n",
    "predicted = scaler.inverse_transform(predicted_normalized.reshape(-1, 3))\n",
    "predicted = predicted.reshape(-1, grid_size, grid_size, 3)\n",
    "\n",
    "# Denormalize the actual test data\n",
    "actual = scaler.inverse_transform(y_test.reshape(-1, 3))\n",
    "actual = actual.reshape(-1, grid_size, grid_size, 3)\n",
    "\n",
    "# Calculate Mean Squared Error on the denormalized data\n",
    "mae = mean_absolute_error(actual.reshape(-1, 3), predicted.reshape(-1, 3))\n",
    "print(\"Mean Absolute Error on Actual Data:\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca621ba5-2719-4487-ba5e-b6777c04b45d",
   "metadata": {},
   "source": [
    "#### d_i calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d30a23dc-f767-4517-8a19-81416bc7870d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_distance_for_one_atom_over_time(actual, predicted, atom_index, grid_size):\n",
    "    # Determine the row and column in the grid for the atom index\n",
    "    row = atom_index // grid_size\n",
    "    col = atom_index % grid_size\n",
    "\n",
    "    # Extract the coordinates for the specified atom over all time steps\n",
    "    actual_atom_coords = actual[:, row, col, :]\n",
    "    predicted_atom_coords = predicted[:, row, col, :]\n",
    "    \n",
    "    # Calculate and return the Euclidean distances for this atom over all time steps\n",
    "    distances = np.sqrt(np.sum((actual_atom_coords - predicted_atom_coords) ** 2, axis=1))\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe8ceec-58f4-4d14-97f2-297059215eeb",
   "metadata": {},
   "source": [
    "#### TM-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "614845ee-951a-4eaa-b1e6-e17fe165f15d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The TM-score for all atoms across all time steps is: 0.9999994634713573\n"
     ]
    }
   ],
   "source": [
    "# L_target is the total number of atoms in the protein structure.\n",
    "L_target = num_res\n",
    "L_common = num_res\n",
    "grid_size = int(np.ceil(np.sqrt(L_target)))  # Calculate grid size dynamically\n",
    "\n",
    "# Calculate d0, the normalization factor\n",
    "d0 = 1.24 * np.cbrt(L_target - 15) - 1.8\n",
    "\n",
    "# Initialize the TM-score sum\n",
    "tm_score_sum = 0\n",
    "\n",
    "# Iterate over all atoms to calculate the distance and contribute to the TM-score sum\n",
    "for atom_index in range(L_common):\n",
    "    distances = calculate_distance_for_one_atom_over_time(actual, predicted, atom_index, grid_size)\n",
    "    tm_score_sum += np.sum(1 / (1 + (distances / d0) ** 2))\n",
    "\n",
    "# Normalize the TM-score sum by the length of the target protein to get the final TM-score\n",
    "tm_score = tm_score_sum / (L_target * actual.shape[0])\n",
    "\n",
    "print(f\"The TM-score for all atoms across all time steps is: {tm_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184742e7",
   "metadata": {},
   "source": [
    "##### Resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "55baaada",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Reshape\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fcbf7ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(atomic_coordinates, num_res):\n",
    "    scaler = StandardScaler()\n",
    "    positions_normalized = scaler.fit_transform(atomic_coordinates.reshape(-1, atomic_coordinates.shape[-1])).reshape(atomic_coordinates.shape)\n",
    "\n",
    "    grid_size = int(math.ceil(math.sqrt(num_res)))\n",
    "\n",
    "    reshaped_data = np.zeros((positions_normalized.shape[0], grid_size, grid_size, 3))  # Dynamically sized grid\n",
    "\n",
    "    for i in range(positions_normalized.shape[0]):\n",
    "        for j in range(num_res):\n",
    "            row = j // grid_size\n",
    "            col = j % grid_size\n",
    "            reshaped_data[i, row, col, :] = positions_normalized[i, j, :]\n",
    "\n",
    "    X = reshaped_data[:-1]\n",
    "    y = reshaped_data[1:]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    return X_train, X_test, y_train, y_test, scaler, grid_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "14188e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the ResNet50 model\n",
    "def build_resnet50_model(grid_size):\n",
    "    input_layer = Input(shape=(grid_size, grid_size, 3))\n",
    "    base_model = ResNet50(include_top=False, weights=None, input_tensor=input_layer)\n",
    "    x = Flatten()(base_model.output)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dense(grid_size * grid_size * 3)(x)\n",
    "    output_layer = Reshape((grid_size, grid_size, 3))(x)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    model.compile(optimizer='adam', loss='mean_absolute_error')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d96f7579",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, scaler, grid_size = preprocess_data(atomic_coordinates, num_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dc108aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_resnet50_model(grid_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "63c09db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_6 (InputLayer)        [(None, 41, 41, 3)]          0         []                            \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)   (None, 47, 47, 3)            0         ['input_6[0][0]']             \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)         (None, 21, 21, 64)           9472      ['conv1_pad[0][0]']           \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalizati  (None, 21, 21, 64)           256       ['conv1_conv[0][0]']          \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv1_relu (Activation)     (None, 21, 21, 64)           0         ['conv1_bn[0][0]']            \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)   (None, 23, 23, 64)           0         ['conv1_relu[0][0]']          \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)   (None, 11, 11, 64)           0         ['pool1_pad[0][0]']           \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2  (None, 11, 11, 64)           4160      ['pool1_pool[0][0]']          \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNo  (None, 11, 11, 64)           256       ['conv2_block1_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activ  (None, 11, 11, 64)           0         ['conv2_block1_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2  (None, 11, 11, 64)           36928     ['conv2_block1_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNo  (None, 11, 11, 64)           256       ['conv2_block1_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activ  (None, 11, 11, 64)           0         ['conv2_block1_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2  (None, 11, 11, 256)          16640     ['pool1_pool[0][0]']          \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2  (None, 11, 11, 256)          16640     ['conv2_block1_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNo  (None, 11, 11, 256)          1024      ['conv2_block1_0_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block1_3_bn (BatchNo  (None, 11, 11, 256)          1024      ['conv2_block1_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block1_add (Add)      (None, 11, 11, 256)          0         ['conv2_block1_0_bn[0][0]',   \n",
      "                                                                     'conv2_block1_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv2_block1_out (Activati  (None, 11, 11, 256)          0         ['conv2_block1_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2  (None, 11, 11, 64)           16448     ['conv2_block1_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNo  (None, 11, 11, 64)           256       ['conv2_block2_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activ  (None, 11, 11, 64)           0         ['conv2_block2_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2  (None, 11, 11, 64)           36928     ['conv2_block2_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNo  (None, 11, 11, 64)           256       ['conv2_block2_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activ  (None, 11, 11, 64)           0         ['conv2_block2_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2  (None, 11, 11, 256)          16640     ['conv2_block2_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_bn (BatchNo  (None, 11, 11, 256)          1024      ['conv2_block2_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block2_add (Add)      (None, 11, 11, 256)          0         ['conv2_block1_out[0][0]',    \n",
      "                                                                     'conv2_block2_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv2_block2_out (Activati  (None, 11, 11, 256)          0         ['conv2_block2_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2  (None, 11, 11, 64)           16448     ['conv2_block2_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNo  (None, 11, 11, 64)           256       ['conv2_block3_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activ  (None, 11, 11, 64)           0         ['conv2_block3_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2  (None, 11, 11, 64)           36928     ['conv2_block3_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNo  (None, 11, 11, 64)           256       ['conv2_block3_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activ  (None, 11, 11, 64)           0         ['conv2_block3_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2  (None, 11, 11, 256)          16640     ['conv2_block3_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_3_bn (BatchNo  (None, 11, 11, 256)          1024      ['conv2_block3_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block3_add (Add)      (None, 11, 11, 256)          0         ['conv2_block2_out[0][0]',    \n",
      "                                                                     'conv2_block3_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv2_block3_out (Activati  (None, 11, 11, 256)          0         ['conv2_block3_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2  (None, 6, 6, 128)            32896     ['conv2_block3_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNo  (None, 6, 6, 128)            512       ['conv3_block1_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activ  (None, 6, 6, 128)            0         ['conv3_block1_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2  (None, 6, 6, 128)            147584    ['conv3_block1_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNo  (None, 6, 6, 128)            512       ['conv3_block1_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activ  (None, 6, 6, 128)            0         ['conv3_block1_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2  (None, 6, 6, 512)            131584    ['conv2_block3_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2  (None, 6, 6, 512)            66048     ['conv3_block1_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNo  (None, 6, 6, 512)            2048      ['conv3_block1_0_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block1_3_bn (BatchNo  (None, 6, 6, 512)            2048      ['conv3_block1_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block1_add (Add)      (None, 6, 6, 512)            0         ['conv3_block1_0_bn[0][0]',   \n",
      "                                                                     'conv3_block1_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block1_out (Activati  (None, 6, 6, 512)            0         ['conv3_block1_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2  (None, 6, 6, 128)            65664     ['conv3_block1_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNo  (None, 6, 6, 128)            512       ['conv3_block2_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activ  (None, 6, 6, 128)            0         ['conv3_block2_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2  (None, 6, 6, 128)            147584    ['conv3_block2_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNo  (None, 6, 6, 128)            512       ['conv3_block2_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activ  (None, 6, 6, 128)            0         ['conv3_block2_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2  (None, 6, 6, 512)            66048     ['conv3_block2_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_bn (BatchNo  (None, 6, 6, 512)            2048      ['conv3_block2_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block2_add (Add)      (None, 6, 6, 512)            0         ['conv3_block1_out[0][0]',    \n",
      "                                                                     'conv3_block2_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block2_out (Activati  (None, 6, 6, 512)            0         ['conv3_block2_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2  (None, 6, 6, 128)            65664     ['conv3_block2_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNo  (None, 6, 6, 128)            512       ['conv3_block3_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activ  (None, 6, 6, 128)            0         ['conv3_block3_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2  (None, 6, 6, 128)            147584    ['conv3_block3_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNo  (None, 6, 6, 128)            512       ['conv3_block3_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activ  (None, 6, 6, 128)            0         ['conv3_block3_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2  (None, 6, 6, 512)            66048     ['conv3_block3_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_bn (BatchNo  (None, 6, 6, 512)            2048      ['conv3_block3_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block3_add (Add)      (None, 6, 6, 512)            0         ['conv3_block2_out[0][0]',    \n",
      "                                                                     'conv3_block3_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block3_out (Activati  (None, 6, 6, 512)            0         ['conv3_block3_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2  (None, 6, 6, 128)            65664     ['conv3_block3_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNo  (None, 6, 6, 128)            512       ['conv3_block4_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activ  (None, 6, 6, 128)            0         ['conv3_block4_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2  (None, 6, 6, 128)            147584    ['conv3_block4_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNo  (None, 6, 6, 128)            512       ['conv3_block4_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activ  (None, 6, 6, 128)            0         ['conv3_block4_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2  (None, 6, 6, 512)            66048     ['conv3_block4_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_3_bn (BatchNo  (None, 6, 6, 512)            2048      ['conv3_block4_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block4_add (Add)      (None, 6, 6, 512)            0         ['conv3_block3_out[0][0]',    \n",
      "                                                                     'conv3_block4_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block4_out (Activati  (None, 6, 6, 512)            0         ['conv3_block4_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2  (None, 3, 3, 256)            131328    ['conv3_block4_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNo  (None, 3, 3, 256)            1024      ['conv4_block1_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activ  (None, 3, 3, 256)            0         ['conv4_block1_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2  (None, 3, 3, 256)            590080    ['conv4_block1_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNo  (None, 3, 3, 256)            1024      ['conv4_block1_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activ  (None, 3, 3, 256)            0         ['conv4_block1_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2  (None, 3, 3, 1024)           525312    ['conv3_block4_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2  (None, 3, 3, 1024)           263168    ['conv4_block1_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNo  (None, 3, 3, 1024)           4096      ['conv4_block1_0_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block1_3_bn (BatchNo  (None, 3, 3, 1024)           4096      ['conv4_block1_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block1_add (Add)      (None, 3, 3, 1024)           0         ['conv4_block1_0_bn[0][0]',   \n",
      "                                                                     'conv4_block1_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block1_out (Activati  (None, 3, 3, 1024)           0         ['conv4_block1_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2  (None, 3, 3, 256)            262400    ['conv4_block1_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNo  (None, 3, 3, 256)            1024      ['conv4_block2_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activ  (None, 3, 3, 256)            0         ['conv4_block2_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2  (None, 3, 3, 256)            590080    ['conv4_block2_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNo  (None, 3, 3, 256)            1024      ['conv4_block2_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activ  (None, 3, 3, 256)            0         ['conv4_block2_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2  (None, 3, 3, 1024)           263168    ['conv4_block2_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_bn (BatchNo  (None, 3, 3, 1024)           4096      ['conv4_block2_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block2_add (Add)      (None, 3, 3, 1024)           0         ['conv4_block1_out[0][0]',    \n",
      "                                                                     'conv4_block2_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block2_out (Activati  (None, 3, 3, 1024)           0         ['conv4_block2_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2  (None, 3, 3, 256)            262400    ['conv4_block2_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNo  (None, 3, 3, 256)            1024      ['conv4_block3_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activ  (None, 3, 3, 256)            0         ['conv4_block3_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2  (None, 3, 3, 256)            590080    ['conv4_block3_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNo  (None, 3, 3, 256)            1024      ['conv4_block3_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activ  (None, 3, 3, 256)            0         ['conv4_block3_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2  (None, 3, 3, 1024)           263168    ['conv4_block3_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_bn (BatchNo  (None, 3, 3, 1024)           4096      ['conv4_block3_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block3_add (Add)      (None, 3, 3, 1024)           0         ['conv4_block2_out[0][0]',    \n",
      "                                                                     'conv4_block3_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block3_out (Activati  (None, 3, 3, 1024)           0         ['conv4_block3_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2  (None, 3, 3, 256)            262400    ['conv4_block3_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNo  (None, 3, 3, 256)            1024      ['conv4_block4_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activ  (None, 3, 3, 256)            0         ['conv4_block4_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2  (None, 3, 3, 256)            590080    ['conv4_block4_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNo  (None, 3, 3, 256)            1024      ['conv4_block4_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activ  (None, 3, 3, 256)            0         ['conv4_block4_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2  (None, 3, 3, 1024)           263168    ['conv4_block4_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_bn (BatchNo  (None, 3, 3, 1024)           4096      ['conv4_block4_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block4_add (Add)      (None, 3, 3, 1024)           0         ['conv4_block3_out[0][0]',    \n",
      "                                                                     'conv4_block4_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block4_out (Activati  (None, 3, 3, 1024)           0         ['conv4_block4_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2  (None, 3, 3, 256)            262400    ['conv4_block4_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNo  (None, 3, 3, 256)            1024      ['conv4_block5_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activ  (None, 3, 3, 256)            0         ['conv4_block5_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2  (None, 3, 3, 256)            590080    ['conv4_block5_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNo  (None, 3, 3, 256)            1024      ['conv4_block5_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activ  (None, 3, 3, 256)            0         ['conv4_block5_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2  (None, 3, 3, 1024)           263168    ['conv4_block5_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_bn (BatchNo  (None, 3, 3, 1024)           4096      ['conv4_block5_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block5_add (Add)      (None, 3, 3, 1024)           0         ['conv4_block4_out[0][0]',    \n",
      "                                                                     'conv4_block5_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block5_out (Activati  (None, 3, 3, 1024)           0         ['conv4_block5_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2  (None, 3, 3, 256)            262400    ['conv4_block5_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNo  (None, 3, 3, 256)            1024      ['conv4_block6_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activ  (None, 3, 3, 256)            0         ['conv4_block6_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2  (None, 3, 3, 256)            590080    ['conv4_block6_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNo  (None, 3, 3, 256)            1024      ['conv4_block6_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activ  (None, 3, 3, 256)            0         ['conv4_block6_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2  (None, 3, 3, 1024)           263168    ['conv4_block6_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_3_bn (BatchNo  (None, 3, 3, 1024)           4096      ['conv4_block6_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block6_add (Add)      (None, 3, 3, 1024)           0         ['conv4_block5_out[0][0]',    \n",
      "                                                                     'conv4_block6_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block6_out (Activati  (None, 3, 3, 1024)           0         ['conv4_block6_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2  (None, 2, 2, 512)            524800    ['conv4_block6_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNo  (None, 2, 2, 512)            2048      ['conv5_block1_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activ  (None, 2, 2, 512)            0         ['conv5_block1_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2  (None, 2, 2, 512)            2359808   ['conv5_block1_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNo  (None, 2, 2, 512)            2048      ['conv5_block1_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activ  (None, 2, 2, 512)            0         ['conv5_block1_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2  (None, 2, 2, 2048)           2099200   ['conv4_block6_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2  (None, 2, 2, 2048)           1050624   ['conv5_block1_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_bn (BatchNo  (None, 2, 2, 2048)           8192      ['conv5_block1_0_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block1_3_bn (BatchNo  (None, 2, 2, 2048)           8192      ['conv5_block1_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block1_add (Add)      (None, 2, 2, 2048)           0         ['conv5_block1_0_bn[0][0]',   \n",
      "                                                                     'conv5_block1_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block1_out (Activati  (None, 2, 2, 2048)           0         ['conv5_block1_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2  (None, 2, 2, 512)            1049088   ['conv5_block1_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNo  (None, 2, 2, 512)            2048      ['conv5_block2_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activ  (None, 2, 2, 512)            0         ['conv5_block2_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2  (None, 2, 2, 512)            2359808   ['conv5_block2_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNo  (None, 2, 2, 512)            2048      ['conv5_block2_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activ  (None, 2, 2, 512)            0         ['conv5_block2_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2  (None, 2, 2, 2048)           1050624   ['conv5_block2_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_bn (BatchNo  (None, 2, 2, 2048)           8192      ['conv5_block2_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block2_add (Add)      (None, 2, 2, 2048)           0         ['conv5_block1_out[0][0]',    \n",
      "                                                                     'conv5_block2_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block2_out (Activati  (None, 2, 2, 2048)           0         ['conv5_block2_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2  (None, 2, 2, 512)            1049088   ['conv5_block2_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNo  (None, 2, 2, 512)            2048      ['conv5_block3_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activ  (None, 2, 2, 512)            0         ['conv5_block3_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2  (None, 2, 2, 512)            2359808   ['conv5_block3_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNo  (None, 2, 2, 512)            2048      ['conv5_block3_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activ  (None, 2, 2, 512)            0         ['conv5_block3_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2  (None, 2, 2, 2048)           1050624   ['conv5_block3_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_3_bn (BatchNo  (None, 2, 2, 2048)           8192      ['conv5_block3_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block3_add (Add)      (None, 2, 2, 2048)           0         ['conv5_block2_out[0][0]',    \n",
      "                                                                     'conv5_block3_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block3_out (Activati  (None, 2, 2, 2048)           0         ['conv5_block3_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)         (None, 8192)                 0         ['conv5_block3_out[0][0]']    \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 128)                  1048704   ['flatten_2[0][0]']           \n",
      "                                                                                                  \n",
      " dense_5 (Dense)             (None, 5043)                 650547    ['dense_4[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_2 (Reshape)         (None, 41, 41, 3)            0         ['dense_5[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 25286963 (96.46 MB)\n",
      "Trainable params: 25233843 (96.26 MB)\n",
      "Non-trainable params: 53120 (207.50 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e033123a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "20/20 [==============================] - 28s 115ms/step - loss: 0.8194 - val_loss: 0.8072\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.8003 - val_loss: 0.7900\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.7832 - val_loss: 0.7730\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.7663 - val_loss: 0.7563\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.7498 - val_loss: 0.7399\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.7335 - val_loss: 0.7237\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.7175 - val_loss: 0.7078\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.7017 - val_loss: 0.6921\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.6862 - val_loss: 0.6767\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.6710 - val_loss: 0.6616\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.6560 - val_loss: 0.6467\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.6413 - val_loss: 0.6321\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.6268 - val_loss: 0.6177\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.6126 - val_loss: 0.6036\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.5986 - val_loss: 0.5897\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.5849 - val_loss: 0.5761\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.5714 - val_loss: 0.5627\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.5581 - val_loss: 0.5495\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.5451 - val_loss: 0.5366\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.5324 - val_loss: 0.5240\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.5199 - val_loss: 0.5116\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.5076 - val_loss: 0.4995\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.4956 - val_loss: 0.4875\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.4839 - val_loss: 0.4759\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.4723 - val_loss: 0.4645\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.4611 - val_loss: 0.4533\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.4500 - val_loss: 0.4423\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.4391 - val_loss: 0.4316\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.4285 - val_loss: 0.4210\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.4182 - val_loss: 0.4108\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.4080 - val_loss: 0.4007\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.3981 - val_loss: 0.3909\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.3884 - val_loss: 0.3813\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.3789 - val_loss: 0.3719\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.3696 - val_loss: 0.3628\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.3606 - val_loss: 0.3539\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.3518 - val_loss: 0.3452\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.3432 - val_loss: 0.3367\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.3348 - val_loss: 0.3284\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.3267 - val_loss: 0.3204\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.3187 - val_loss: 0.3126\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.3110 - val_loss: 0.3050\n",
      "Epoch 43/100\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.3035 - val_loss: 0.2976\n",
      "Epoch 44/100\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.2962 - val_loss: 0.2903\n",
      "Epoch 45/100\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.2890 - val_loss: 0.2832\n",
      "Epoch 46/100\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.2821 - val_loss: 0.2764\n",
      "Epoch 47/100\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.2754 - val_loss: 0.2698\n",
      "Epoch 48/100\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.2688 - val_loss: 0.2633\n",
      "Epoch 49/100\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.2625 - val_loss: 0.2571\n",
      "Epoch 50/100\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.2563 - val_loss: 0.2510\n",
      "Epoch 51/100\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.2503 - val_loss: 0.2451\n",
      "Epoch 52/100\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.2445 - val_loss: 0.2395\n",
      "Epoch 53/100\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.2390 - val_loss: 0.2340\n",
      "Epoch 54/100\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.2336 - val_loss: 0.2287\n",
      "Epoch 55/100\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.2284 - val_loss: 0.2236\n",
      "Epoch 56/100\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.2234 - val_loss: 0.2187\n",
      "Epoch 57/100\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.2185 - val_loss: 0.2140\n",
      "Epoch 58/100\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.2139 - val_loss: 0.2095\n",
      "Epoch 59/100\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.2094 - val_loss: 0.2050\n",
      "Epoch 60/100\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.2052 - val_loss: 0.2008\n",
      "Epoch 61/100\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.2010 - val_loss: 0.1969\n",
      "Epoch 62/100\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.1971 - val_loss: 0.1930\n",
      "Epoch 63/100\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.1933 - val_loss: 0.1894\n",
      "Epoch 64/100\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.1897 - val_loss: 0.1858\n",
      "Epoch 65/100\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.1862 - val_loss: 0.1824\n",
      "Epoch 66/100\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.1829 - val_loss: 0.1793\n",
      "Epoch 67/100\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.1798 - val_loss: 0.1762\n",
      "Epoch 68/100\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.1768 - val_loss: 0.1733\n",
      "Epoch 69/100\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.1740 - val_loss: 0.1705\n",
      "Epoch 70/100\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.1713 - val_loss: 0.1679\n",
      "Epoch 71/100\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.1687 - val_loss: 0.1654\n",
      "Epoch 72/100\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.1663 - val_loss: 0.1631\n",
      "Epoch 73/100\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.1640 - val_loss: 0.1609\n",
      "Epoch 74/100\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.1618 - val_loss: 0.1587\n",
      "Epoch 75/100\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.1598 - val_loss: 0.1568\n",
      "Epoch 76/100\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.1578 - val_loss: 0.1549\n",
      "Epoch 77/100\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.1560 - val_loss: 0.1531\n",
      "Epoch 78/100\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.1543 - val_loss: 0.1515\n",
      "Epoch 79/100\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.1527 - val_loss: 0.1499\n",
      "Epoch 80/100\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.1512 - val_loss: 0.1485\n",
      "Epoch 81/100\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.1499 - val_loss: 0.1472\n",
      "Epoch 82/100\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.1486 - val_loss: 0.1460\n",
      "Epoch 83/100\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.1474 - val_loss: 0.1449\n",
      "Epoch 84/100\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.1463 - val_loss: 0.1438\n",
      "Epoch 85/100\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.1453 - val_loss: 0.1428\n",
      "Epoch 86/100\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.1444 - val_loss: 0.1420\n",
      "Epoch 87/100\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.1435 - val_loss: 0.1412\n",
      "Epoch 88/100\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.1427 - val_loss: 0.1404\n",
      "Epoch 89/100\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.1420 - val_loss: 0.1397\n",
      "Epoch 90/100\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.1413 - val_loss: 0.1390\n",
      "Epoch 91/100\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.1407 - val_loss: 0.1385\n",
      "Epoch 92/100\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.1401 - val_loss: 0.1380\n",
      "Epoch 93/100\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.1396 - val_loss: 0.1374\n",
      "Epoch 94/100\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.1391 - val_loss: 0.1370\n",
      "Epoch 95/100\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.1387 - val_loss: 0.1366\n",
      "Epoch 96/100\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.1383 - val_loss: 0.1362\n",
      "Epoch 97/100\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.1380 - val_loss: 0.1359\n",
      "Epoch 98/100\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.1377 - val_loss: 0.1357\n",
      "Epoch 99/100\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.1374 - val_loss: 0.1354\n",
      "Epoch 100/100\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.1372 - val_loss: 0.1352\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fefcc15f3a0>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=100, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "da804f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 36ms/step - loss: 0.1326\n",
      "Test loss: 0.1326153427362442\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss = model.evaluate(X_test, y_test)\n",
    "print(f\"Test loss: {loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b381157",
   "metadata": {},
   "source": [
    "#### Denormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5eb3df8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 4ms/step\n",
      "Mean Absolute Error on Actual Data: 0.02372708994940061\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Grid dimensions based on the dataset\n",
    "grid_size = int(math.ceil(np.sqrt(num_res)))  # Assuming num_residues has been calculated as the nearest perfect square\n",
    "\n",
    "# Predict using the model on normalized test data\n",
    "predicted_normalized = model.predict(X_test)\n",
    "\n",
    "# Denormalize the predicted data\n",
    "predicted = scaler.inverse_transform(predicted_normalized.reshape(-1, 3))\n",
    "predicted = predicted.reshape(-1, grid_size, grid_size, 3)\n",
    "\n",
    "# Denormalize the actual test data\n",
    "actual = scaler.inverse_transform(y_test.reshape(-1, 3))\n",
    "actual = actual.reshape(-1, grid_size, grid_size, 3)\n",
    "\n",
    "# Calculate Mean Squared Error on the denormalized data\n",
    "mae = mean_absolute_error(actual.reshape(-1, 3), predicted.reshape(-1, 3))\n",
    "print(\"Mean Absolute Error on Actual Data:\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0020d41",
   "metadata": {},
   "source": [
    "#### d_i calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "89fc7ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_distance_for_one_atom_over_time(actual, predicted, atom_index, grid_size):\n",
    "    # Determine the row and column in the grid for the atom index\n",
    "    row = atom_index // grid_size\n",
    "    col = atom_index % grid_size\n",
    "\n",
    "    # Extract the coordinates for the specified atom over all time steps\n",
    "    actual_atom_coords = actual[:, row, col, :]\n",
    "    predicted_atom_coords = predicted[:, row, col, :]\n",
    "    \n",
    "    # Calculate and return the Euclidean distances for this atom over all time steps\n",
    "    distances = np.sqrt(np.sum((actual_atom_coords - predicted_atom_coords) ** 2, axis=1))\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fa8c5f",
   "metadata": {},
   "source": [
    "##### TM-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "afaa6276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The TM-score for all atoms across all time steps is: 0.9999779693213898\n"
     ]
    }
   ],
   "source": [
    "# L_target is the total number of atoms in the protein structure.\n",
    "L_target = num_res\n",
    "L_common = num_res\n",
    "grid_size = int(np.ceil(np.sqrt(L_target)))  # Calculate grid size dynamically\n",
    "\n",
    "# Calculate d0, the normalization factor\n",
    "d0 = 1.24 * np.cbrt(L_target - 15) - 1.8\n",
    "\n",
    "# Initialize the TM-score sum\n",
    "tm_score_sum = 0\n",
    "\n",
    "# Iterate over all atoms to calculate the distance and contribute to the TM-score sum\n",
    "for atom_index in range(L_common):\n",
    "    distances = calculate_distance_for_one_atom_over_time(actual, predicted, atom_index, grid_size)\n",
    "    tm_score_sum += np.sum(1 / (1 + (distances / d0) ** 2))\n",
    "\n",
    "# Normalize the TM-score sum by the length of the target protein to get the final TM-score\n",
    "tm_score = tm_score_sum / (L_target * actual.shape[0])\n",
    "\n",
    "print(f\"The TM-score for all atoms across all time steps is: {tm_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744752b6",
   "metadata": {},
   "source": [
    "##### Alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b2741e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Reshape, BatchNormalization, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "945aadff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(atomic_coordinates, num_res):\n",
    "    scaler = StandardScaler()\n",
    "    positions_normalized = scaler.fit_transform(atomic_coordinates.reshape(-1, atomic_coordinates.shape[-1])).reshape(atomic_coordinates.shape)\n",
    "\n",
    "    grid_size = int(math.ceil(math.sqrt(num_res)))\n",
    "\n",
    "    reshaped_data = np.zeros((positions_normalized.shape[0], grid_size, grid_size, 3))  # Dynamically sized grid\n",
    "\n",
    "    for i in range(positions_normalized.shape[0]):\n",
    "        for j in range(num_res):\n",
    "            row = j // grid_size\n",
    "            col = j % grid_size\n",
    "            reshaped_data[i, row, col, :] = positions_normalized[i, j, :]\n",
    "\n",
    "    X = reshaped_data[:-1]\n",
    "    y = reshaped_data[1:]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    return X_train, X_test, y_train, y_test, scaler, grid_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c9df07d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the AlexNet model\n",
    "def build_alexnet_model(grid_size):\n",
    "    input_layer = Input(shape=(grid_size, grid_size, 3))\n",
    "    \n",
    "    x = Conv2D(96, (3, 3), strides=1, activation='relu', padding='same')(input_layer)\n",
    "    x = MaxPooling2D((2, 2), strides=2)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=2)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    x = Conv2D(384, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = Conv2D(384, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=2)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(4096, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(4096, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(grid_size * grid_size * 3)(x)  # Output layer with units to match reshaped data\n",
    "    output_layer = Reshape((grid_size, grid_size, 3))(x)  # Reshape output to match target data shape\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    model.compile(optimizer='adam', loss='mean_absolute_error')\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "15318922",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, scaler, grid_size = preprocess_data(atomic_coordinates, num_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8a82e707",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_alexnet_model(grid_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5afca909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 41, 41, 3)]       0         \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 41, 41, 96)        2688      \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPoolin  (None, 20, 20, 96)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_8 (Bat  (None, 20, 20, 96)        384       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 20, 20, 256)       221440    \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPooli  (None, 10, 10, 256)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " batch_normalization_9 (Bat  (None, 10, 10, 256)       1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 10, 10, 384)       885120    \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 10, 10, 384)       1327488   \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 10, 10, 256)       884992    \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPooli  (None, 5, 5, 256)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " batch_normalization_10 (Ba  (None, 5, 5, 256)         1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 6400)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 4096)              26218496  \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 5043)              20661171  \n",
      "                                                                 \n",
      " reshape_2 (Reshape)         (None, 41, 41, 3)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66985139 (255.53 MB)\n",
      "Trainable params: 66983923 (255.52 MB)\n",
      "Non-trainable params: 1216 (4.75 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "27a578ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "20/20 [==============================] - 3s 19ms/step - loss: 0.5364 - val_loss: 0.5175\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.2491 - val_loss: 0.6010\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.1960 - val_loss: 0.4850\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.1711 - val_loss: 0.4784\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.1646 - val_loss: 0.4598\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.1652 - val_loss: 0.4712\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.1775 - val_loss: 0.4918\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.1781 - val_loss: 0.4317\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.1501 - val_loss: 0.4413\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.1446 - val_loss: 0.4109\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.1472 - val_loss: 0.4398\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.1543 - val_loss: 0.3984\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.1517 - val_loss: 0.4090\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.1467 - val_loss: 0.3763\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.1487 - val_loss: 0.3729\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.1495 - val_loss: 0.3374\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.1462 - val_loss: 0.3643\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.1369 - val_loss: 0.3034\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.1299 - val_loss: 0.3449\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.1253 - val_loss: 0.3258\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.1258 - val_loss: 0.2658\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.1327 - val_loss: 0.3097\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.1243 - val_loss: 0.2382\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 18ms/step - loss: 0.1182 - val_loss: 0.2642\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.1144 - val_loss: 0.2541\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.1103 - val_loss: 0.2556\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.1133 - val_loss: 0.1975\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.1120 - val_loss: 0.2116\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.1103 - val_loss: 0.1850\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.1123 - val_loss: 0.1799\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.1137 - val_loss: 0.1704\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.1047 - val_loss: 0.1259\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.1122 - val_loss: 0.1086\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.1054 - val_loss: 0.1127\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.1051 - val_loss: 0.0961\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.0946 - val_loss: 0.0811\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.0901 - val_loss: 0.0831\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.0879 - val_loss: 0.0828\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.0846 - val_loss: 0.0684\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.0800 - val_loss: 0.0730\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.0823 - val_loss: 0.1080\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.0829 - val_loss: 0.0702\n",
      "Epoch 43/100\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.0847 - val_loss: 0.0793\n",
      "Epoch 44/100\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.0897 - val_loss: 0.0789\n",
      "Epoch 45/100\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.0862 - val_loss: 0.0692\n",
      "Epoch 46/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.0894 - val_loss: 0.0752\n",
      "Epoch 47/100\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.0854 - val_loss: 0.0595\n",
      "Epoch 48/100\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.0865 - val_loss: 0.0662\n",
      "Epoch 49/100\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.0851 - val_loss: 0.0748\n",
      "Epoch 50/100\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 0.0870 - val_loss: 0.0660\n",
      "Epoch 51/100\n",
      "20/20 [==============================] - 2s 119ms/step - loss: 0.0880 - val_loss: 0.0629\n",
      "Epoch 52/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.1094 - val_loss: 0.0925\n",
      "Epoch 53/100\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.1142 - val_loss: 0.0869\n",
      "Epoch 54/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.0895 - val_loss: 0.0987\n",
      "Epoch 55/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.0969 - val_loss: 0.1724\n",
      "Epoch 56/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.0934 - val_loss: 0.1065\n",
      "Epoch 57/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.0901 - val_loss: 0.0848\n",
      "Epoch 58/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.0953 - val_loss: 0.0692\n",
      "Epoch 59/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.0936 - val_loss: 0.0674\n",
      "Epoch 60/100\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 0.0934 - val_loss: 0.0585\n",
      "Epoch 61/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.0888 - val_loss: 0.0660\n",
      "Epoch 62/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.0914 - val_loss: 0.0653\n",
      "Epoch 63/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.0879 - val_loss: 0.0786\n",
      "Epoch 64/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.0917 - val_loss: 0.0688\n",
      "Epoch 65/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.0932 - val_loss: 0.0664\n",
      "Epoch 66/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.0865 - val_loss: 0.0652\n",
      "Epoch 67/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.0839 - val_loss: 0.0695\n",
      "Epoch 68/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.0864 - val_loss: 0.0676\n",
      "Epoch 69/100\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 0.0848 - val_loss: 0.0746\n",
      "Epoch 70/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.0845 - val_loss: 0.0701\n",
      "Epoch 71/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.0861 - val_loss: 0.0637\n",
      "Epoch 72/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.0884 - val_loss: 0.0650\n",
      "Epoch 73/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.0929 - val_loss: 0.0624\n",
      "Epoch 74/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.0946 - val_loss: 0.0718\n",
      "Epoch 75/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.0859 - val_loss: 0.0674\n",
      "Epoch 76/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.0863 - val_loss: 0.0647\n",
      "Epoch 77/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.0833 - val_loss: 0.0625\n",
      "Epoch 78/100\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 0.0852 - val_loss: 0.0684\n",
      "Epoch 79/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.0802 - val_loss: 0.0661\n",
      "Epoch 80/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.0910 - val_loss: 0.0700\n",
      "Epoch 81/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.0784 - val_loss: 0.0692\n",
      "Epoch 82/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.0832 - val_loss: 0.0636\n",
      "Epoch 83/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.0845 - val_loss: 0.0638\n",
      "Epoch 84/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.0844 - val_loss: 0.0743\n",
      "Epoch 85/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.0790 - val_loss: 0.0614\n",
      "Epoch 86/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.0817 - val_loss: 0.0665\n",
      "Epoch 87/100\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 0.0804 - val_loss: 0.0629\n",
      "Epoch 88/100\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.0757 - val_loss: 0.0576\n",
      "Epoch 89/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.0808 - val_loss: 0.0711\n",
      "Epoch 90/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.0813 - val_loss: 0.0797\n",
      "Epoch 91/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.0855 - val_loss: 0.0735\n",
      "Epoch 92/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.0815 - val_loss: 0.0663\n",
      "Epoch 93/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.0818 - val_loss: 0.0635\n",
      "Epoch 94/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.0806 - val_loss: 0.0699\n",
      "Epoch 95/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.0778 - val_loss: 0.0634\n",
      "Epoch 96/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.0842 - val_loss: 0.0636\n",
      "Epoch 97/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.0812 - val_loss: 0.0724\n",
      "Epoch 98/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.0856 - val_loss: 0.0731\n",
      "Epoch 99/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.0835 - val_loss: 0.0630\n",
      "Epoch 100/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.0853 - val_loss: 0.0664\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f6542f23700>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=100, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8a36f7a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0701\n",
      "Test loss: 0.07012642920017242\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss = model.evaluate(X_test, y_test)\n",
    "print(f\"Test loss: {loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e95bf9",
   "metadata": {},
   "source": [
    "##### Denormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5908eaa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 2ms/step\n",
      "Mean Absolute Error on Actual Data: 0.012799374462352494\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Grid dimensions based on the dataset\n",
    "grid_size = int(math.ceil(np.sqrt(num_res)))  # Assuming num_residues has been calculated as the nearest perfect square\n",
    "\n",
    "# Predict using the model on normalized test data\n",
    "predicted_normalized = model.predict(X_test)\n",
    "\n",
    "# Denormalize the predicted data\n",
    "predicted = scaler.inverse_transform(predicted_normalized.reshape(-1, 3))\n",
    "predicted = predicted.reshape(-1, grid_size, grid_size, 3)\n",
    "\n",
    "# Denormalize the actual test data\n",
    "actual = scaler.inverse_transform(y_test.reshape(-1, 3))\n",
    "actual = actual.reshape(-1, grid_size, grid_size, 3)\n",
    "\n",
    "# Calculate Mean Squared Error on the denormalized data\n",
    "mae = mean_absolute_error(actual.reshape(-1, 3), predicted.reshape(-1, 3))\n",
    "print(\"Mean Absolute Error on Actual Data:\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847a52d1",
   "metadata": {},
   "source": [
    "##### d_i Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "990e5b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_distance_for_one_atom_over_time(actual, predicted, atom_index, grid_size):\n",
    "    # Determine the row and column in the grid for the atom index\n",
    "    row = atom_index // grid_size\n",
    "    col = atom_index % grid_size\n",
    "\n",
    "    # Extract the coordinates for the specified atom over all time steps\n",
    "    actual_atom_coords = actual[:, row, col, :]\n",
    "    predicted_atom_coords = predicted[:, row, col, :]\n",
    "    \n",
    "    # Calculate and return the Euclidean distances for this atom over all time steps\n",
    "    distances = np.sqrt(np.sum((actual_atom_coords - predicted_atom_coords) ** 2, axis=1))\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed36684",
   "metadata": {},
   "source": [
    "##### TM-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eac525c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The TM-score for all atoms across all time steps is: 0.9999943689849696\n"
     ]
    }
   ],
   "source": [
    "# L_target is the total number of atoms in the protein structure.\n",
    "L_target = num_res\n",
    "L_common = num_res\n",
    "grid_size = int(np.ceil(np.sqrt(L_target)))  # Calculate grid size dynamically\n",
    "\n",
    "# Calculate d0, the normalization factor\n",
    "d0 = 1.24 * np.cbrt(L_target - 15) - 1.8\n",
    "\n",
    "# Initialize the TM-score sum\n",
    "tm_score_sum = 0\n",
    "\n",
    "# Iterate over all atoms to calculate the distance and contribute to the TM-score sum\n",
    "for atom_index in range(L_common):\n",
    "    distances = calculate_distance_for_one_atom_over_time(actual, predicted, atom_index, grid_size)\n",
    "    tm_score_sum += np.sum(1 / (1 + (distances / d0) ** 2))\n",
    "\n",
    "# Normalize the TM-score sum by the length of the target protein to get the final TM-score\n",
    "tm_score = tm_score_sum / (L_target * actual.shape[0])\n",
    "\n",
    "print(f\"The TM-score for all atoms across all time steps is: {tm_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa31fe58",
   "metadata": {},
   "source": [
    "##### Lenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1f1a1368",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Reshape, BatchNormalization, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "367aff2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(atomic_coordinates, num_res):\n",
    "    scaler = StandardScaler()\n",
    "    positions_normalized = scaler.fit_transform(atomic_coordinates.reshape(-1, atomic_coordinates.shape[-1])).reshape(atomic_coordinates.shape)\n",
    "\n",
    "    grid_size = int(math.ceil(math.sqrt(num_res)))\n",
    "\n",
    "    reshaped_data = np.zeros((positions_normalized.shape[0], grid_size, grid_size, 3))  # Dynamically sized grid\n",
    "\n",
    "    for i in range(positions_normalized.shape[0]):\n",
    "        for j in range(num_res):\n",
    "            row = j // grid_size\n",
    "            col = j % grid_size\n",
    "            reshaped_data[i, row, col, :] = positions_normalized[i, j, :]\n",
    "\n",
    "    X = reshaped_data[:-1]\n",
    "    y = reshaped_data[1:]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    return X_train, X_test, y_train, y_test, scaler, grid_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "db4b6da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the LeNet model\n",
    "def build_lenet_model(grid_size):\n",
    "    input_layer = Input(shape=(grid_size, grid_size, 3))\n",
    "    \n",
    "    x = Conv2D(6, (5, 5), activation='relu', padding='same')(input_layer)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    x = Conv2D(16, (5, 5), activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(120, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(84, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(grid_size * grid_size * 3)(x)  # Output layer with units to match reshaped data\n",
    "    output_layer = Reshape((grid_size, grid_size, 3))(x)  # Reshape output to match target data shape\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    model.compile(optimizer='adam', loss='mean_absolute_error')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d1e9ad6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, scaler, grid_size = preprocess_data(atomic_coordinates, num_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9d2e1107",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_lenet_model(grid_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "661fb535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 41, 41, 3)]       0         \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 41, 41, 6)         456       \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPooli  (None, 20, 20, 6)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " batch_normalization_11 (Ba  (None, 20, 20, 6)         24        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 20, 20, 16)        2416      \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPooli  (None, 10, 10, 16)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " batch_normalization_12 (Ba  (None, 10, 10, 16)        64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 1600)              0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 120)               192120    \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 120)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 84)                10164     \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 84)                0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 5043)              428655    \n",
      "                                                                 \n",
      " reshape_3 (Reshape)         (None, 41, 41, 3)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 633899 (2.42 MB)\n",
      "Trainable params: 633855 (2.42 MB)\n",
      "Non-trainable params: 44 (176.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1dba377c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "20/20 [==============================] - 3s 20ms/step - loss: 0.5370 - val_loss: 0.6684\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.3041 - val_loss: 0.6093\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.2643 - val_loss: 0.5783\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.2315 - val_loss: 0.5742\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.2429 - val_loss: 0.4961\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.2267 - val_loss: 0.4873\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.2143 - val_loss: 0.5109\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.1910 - val_loss: 0.4768\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.1949 - val_loss: 0.4497\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.1986 - val_loss: 0.4162\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.1953 - val_loss: 0.4359\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.1813 - val_loss: 0.4251\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.1841 - val_loss: 0.4090\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.1876 - val_loss: 0.3727\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.1768 - val_loss: 0.3691\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.1767 - val_loss: 0.3959\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.1766 - val_loss: 0.3512\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.1742 - val_loss: 0.3532\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.1744 - val_loss: 0.3463\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.1748 - val_loss: 0.3240\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.1690 - val_loss: 0.3132\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.1689 - val_loss: 0.3215\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.1610 - val_loss: 0.3513\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.1618 - val_loss: 0.2975\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.1605 - val_loss: 0.3204\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.1631 - val_loss: 0.3228\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.1638 - val_loss: 0.2672\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.1583 - val_loss: 0.2880\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.1554 - val_loss: 0.2593\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.1555 - val_loss: 0.2730\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.1501 - val_loss: 0.2438\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.1534 - val_loss: 0.2604\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.1523 - val_loss: 0.2386\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.1490 - val_loss: 0.2532\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.1489 - val_loss: 0.2170\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.1379 - val_loss: 0.2392\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.1415 - val_loss: 0.2151\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.1441 - val_loss: 0.2212\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.1420 - val_loss: 0.2215\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.1422 - val_loss: 0.1804\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.1336 - val_loss: 0.1861\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.1362 - val_loss: 0.1817\n",
      "Epoch 43/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.1308 - val_loss: 0.1835\n",
      "Epoch 44/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.1351 - val_loss: 0.1524\n",
      "Epoch 45/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.1240 - val_loss: 0.1397\n",
      "Epoch 46/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.1214 - val_loss: 0.1164\n",
      "Epoch 47/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.1195 - val_loss: 0.0982\n",
      "Epoch 48/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.1159 - val_loss: 0.0920\n",
      "Epoch 49/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.1138 - val_loss: 0.0828\n",
      "Epoch 50/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.1108 - val_loss: 0.0823\n",
      "Epoch 51/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.1091 - val_loss: 0.0857\n",
      "Epoch 52/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.1135 - val_loss: 0.0877\n",
      "Epoch 53/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.1086 - val_loss: 0.0756\n",
      "Epoch 54/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.1082 - val_loss: 0.0765\n",
      "Epoch 55/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.1075 - val_loss: 0.0714\n",
      "Epoch 56/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.1066 - val_loss: 0.0832\n",
      "Epoch 57/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.1070 - val_loss: 0.0772\n",
      "Epoch 58/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.1118 - val_loss: 0.0783\n",
      "Epoch 59/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.1035 - val_loss: 0.0739\n",
      "Epoch 60/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.1061 - val_loss: 0.0812\n",
      "Epoch 61/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.1078 - val_loss: 0.0824\n",
      "Epoch 62/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.1068 - val_loss: 0.0778\n",
      "Epoch 63/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.1062 - val_loss: 0.0765\n",
      "Epoch 64/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.1086 - val_loss: 0.0703\n",
      "Epoch 65/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.1046 - val_loss: 0.0672\n",
      "Epoch 66/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.1021 - val_loss: 0.0747\n",
      "Epoch 67/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.1000 - val_loss: 0.0746\n",
      "Epoch 68/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.1016 - val_loss: 0.0716\n",
      "Epoch 69/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.0993 - val_loss: 0.0681\n",
      "Epoch 70/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.1029 - val_loss: 0.0728\n",
      "Epoch 71/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.1017 - val_loss: 0.0765\n",
      "Epoch 72/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.1024 - val_loss: 0.0829\n",
      "Epoch 73/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.1001 - val_loss: 0.0790\n",
      "Epoch 74/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.1028 - val_loss: 0.0820\n",
      "Epoch 75/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.0967 - val_loss: 0.0718\n",
      "Epoch 76/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.0996 - val_loss: 0.0731\n",
      "Epoch 77/100\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.0968 - val_loss: 0.0694\n",
      "Epoch 78/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.0964 - val_loss: 0.0727\n",
      "Epoch 79/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.0965 - val_loss: 0.0670\n",
      "Epoch 80/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.0952 - val_loss: 0.0706\n",
      "Epoch 81/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.0963 - val_loss: 0.0708\n",
      "Epoch 82/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.0967 - val_loss: 0.0705\n",
      "Epoch 83/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.0950 - val_loss: 0.0639\n",
      "Epoch 84/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.0932 - val_loss: 0.0685\n",
      "Epoch 85/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.0963 - val_loss: 0.0655\n",
      "Epoch 86/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.0929 - val_loss: 0.0673\n",
      "Epoch 87/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.0939 - val_loss: 0.0709\n",
      "Epoch 88/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.0915 - val_loss: 0.0749\n",
      "Epoch 89/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.0957 - val_loss: 0.0646\n",
      "Epoch 90/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.0979 - val_loss: 0.0712\n",
      "Epoch 91/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.0955 - val_loss: 0.0670\n",
      "Epoch 92/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.0946 - val_loss: 0.0653\n",
      "Epoch 93/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.0910 - val_loss: 0.0653\n",
      "Epoch 94/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.0926 - val_loss: 0.0656\n",
      "Epoch 95/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.0914 - val_loss: 0.0618\n",
      "Epoch 96/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.0918 - val_loss: 0.0664\n",
      "Epoch 97/100\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.0935 - val_loss: 0.0677\n",
      "Epoch 98/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.0914 - val_loss: 0.0672\n",
      "Epoch 99/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.0896 - val_loss: 0.0683\n",
      "Epoch 100/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.0868 - val_loss: 0.0699\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f6542b69d60>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=100, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "52f2970b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0708\n",
      "Test loss: 0.07083191722631454\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss = model.evaluate(X_test, y_test)\n",
    "print(f\"Test loss: {loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d693b100",
   "metadata": {},
   "source": [
    "##### Denormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "258a66da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 1ms/step\n",
      "Mean Absolute Error on Actual Data: 0.01314761748861592\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Grid dimensions based on the dataset\n",
    "grid_size = int(math.ceil(np.sqrt(num_res)))  # Assuming num_residues has been calculated as the nearest perfect square\n",
    "\n",
    "# Predict using the model on normalized test data\n",
    "predicted_normalized = model.predict(X_test)\n",
    "\n",
    "# Denormalize the predicted data\n",
    "predicted = scaler.inverse_transform(predicted_normalized.reshape(-1, 3))\n",
    "predicted = predicted.reshape(-1, grid_size, grid_size, 3)\n",
    "\n",
    "# Denormalize the actual test data\n",
    "actual = scaler.inverse_transform(y_test.reshape(-1, 3))\n",
    "actual = actual.reshape(-1, grid_size, grid_size, 3)\n",
    "\n",
    "# Calculate Mean Squared Error on the denormalized data\n",
    "mae = mean_absolute_error(actual.reshape(-1, 3), predicted.reshape(-1, 3))\n",
    "print(\"Mean Absolute Error on Actual Data:\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e91a0f",
   "metadata": {},
   "source": [
    "##### d_i Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "500b33e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_distance_for_one_atom_over_time(actual, predicted, atom_index, grid_size):\n",
    "    # Determine the row and column in the grid for the atom index\n",
    "    row = atom_index // grid_size\n",
    "    col = atom_index % grid_size\n",
    "\n",
    "    # Extract the coordinates for the specified atom over all time steps\n",
    "    actual_atom_coords = actual[:, row, col, :]\n",
    "    predicted_atom_coords = predicted[:, row, col, :]\n",
    "    \n",
    "    # Calculate and return the Euclidean distances for this atom over all time steps\n",
    "    distances = np.sqrt(np.sum((actual_atom_coords - predicted_atom_coords) ** 2, axis=1))\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ae95e7",
   "metadata": {},
   "source": [
    "##### TM_Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "857bf242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The TM-score for all atoms across all time steps is: 0.9999940412543494\n"
     ]
    }
   ],
   "source": [
    "# L_target is the total number of atoms in the protein structure.\n",
    "L_target = num_res\n",
    "L_common = num_res\n",
    "grid_size = int(np.ceil(np.sqrt(L_target)))  # Calculate grid size dynamically\n",
    "\n",
    "# Calculate d0, the normalization factor\n",
    "d0 = 1.24 * np.cbrt(L_target - 15) - 1.8\n",
    "\n",
    "# Initialize the TM-score sum\n",
    "tm_score_sum = 0\n",
    "\n",
    "# Iterate over all atoms to calculate the distance and contribute to the TM-score sum\n",
    "for atom_index in range(L_common):\n",
    "    distances = calculate_distance_for_one_atom_over_time(actual, predicted, atom_index, grid_size)\n",
    "    tm_score_sum += np.sum(1 / (1 + (distances / d0) ** 2))\n",
    "\n",
    "# Normalize the TM-score sum by the length of the target protein to get the final TM-score\n",
    "tm_score = tm_score_sum / (L_target * actual.shape[0])\n",
    "\n",
    "print(f\"The TM-score for all atoms across all time steps is: {tm_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92394bf",
   "metadata": {},
   "source": [
    "##### VGGNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0d576c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Reshape, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7204fc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(atomic_coordinates, num_res):\n",
    "    scaler = StandardScaler()\n",
    "    positions_normalized = scaler.fit_transform(atomic_coordinates.reshape(-1, atomic_coordinates.shape[-1])).reshape(atomic_coordinates.shape)\n",
    "\n",
    "    grid_size = int(math.ceil(math.sqrt(num_res)))\n",
    "\n",
    "    reshaped_data = np.zeros((positions_normalized.shape[0], grid_size, grid_size, 3))  # Dynamically sized grid\n",
    "\n",
    "    for i in range(positions_normalized.shape[0]):\n",
    "        for j in range(num_res):\n",
    "            row = j // grid_size\n",
    "            col = j % grid_size\n",
    "            reshaped_data[i, row, col, :] = positions_normalized[i, j, :]\n",
    "\n",
    "    X = reshaped_data[:-1]\n",
    "    y = reshaped_data[1:]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    return X_train, X_test, y_train, y_test, scaler, grid_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "426d6bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the VGGNet model\n",
    "def build_vggnet_model(grid_size):\n",
    "    input_layer = Input(shape=(grid_size, grid_size, 3))\n",
    "    \n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(input_layer)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(4096, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(4096, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(grid_size * grid_size * 3)(x)  # Output layer with units to match reshaped data\n",
    "    output_layer = Reshape((grid_size, grid_size, 3))(x)  # Reshape output to match target data shape\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    model.compile(optimizer='adam', loss='mean_absolute_error')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "312847a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, scaler, grid_size = preprocess_data(atomic_coordinates, num_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9ef855f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_vggnet_model(grid_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0460c629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 41, 41, 3)]       0         \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 41, 41, 64)        1792      \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 41, 41, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPooli  (None, 20, 20, 64)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_24 (Conv2D)          (None, 20, 20, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_25 (Conv2D)          (None, 20, 20, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_15 (MaxPooli  (None, 10, 10, 128)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_26 (Conv2D)          (None, 10, 10, 256)       295168    \n",
      "                                                                 \n",
      " conv2d_27 (Conv2D)          (None, 10, 10, 256)       590080    \n",
      "                                                                 \n",
      " conv2d_28 (Conv2D)          (None, 10, 10, 256)       590080    \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPooli  (None, 5, 5, 256)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_29 (Conv2D)          (None, 5, 5, 512)         1180160   \n",
      "                                                                 \n",
      " conv2d_30 (Conv2D)          (None, 5, 5, 512)         2359808   \n",
      "                                                                 \n",
      " conv2d_31 (Conv2D)          (None, 5, 5, 512)         2359808   \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPooli  (None, 2, 2, 512)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_32 (Conv2D)          (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " conv2d_33 (Conv2D)          (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " conv2d_34 (Conv2D)          (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPooli  (None, 1, 1, 512)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 4096)              2101248   \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 5043)              20661171  \n",
      "                                                                 \n",
      " reshape_4 (Reshape)         (None, 41, 41, 3)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 54258419 (206.98 MB)\n",
      "Trainable params: 54258419 (206.98 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0e3425b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "20/20 [==============================] - 5s 47ms/step - loss: 0.7909 - val_loss: 0.4212\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.2305 - val_loss: 0.1567\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.1615 - val_loss: 0.1389\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.1554 - val_loss: 0.1382\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.1539 - val_loss: 0.1362\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.1519 - val_loss: 0.1365\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.1504 - val_loss: 0.1359\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.1499 - val_loss: 0.1371\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.1492 - val_loss: 0.1350\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.1477 - val_loss: 0.1362\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.1477 - val_loss: 0.1355\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.1473 - val_loss: 0.1420\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.1481 - val_loss: 0.1426\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.1475 - val_loss: 0.1352\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.1467 - val_loss: 0.1402\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 18ms/step - loss: 0.1464 - val_loss: 0.1366\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.1445 - val_loss: 0.1389\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.1459 - val_loss: 0.1384\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.1442 - val_loss: 0.1350\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.1444 - val_loss: 0.1344\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.1435 - val_loss: 0.1371\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.1438 - val_loss: 0.1368\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 17ms/step - loss: 0.1429 - val_loss: 0.1355\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 0.1436 - val_loss: 0.1362\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.1434 - val_loss: 0.1346\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.1430 - val_loss: 0.1366\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.1418 - val_loss: 0.1354\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.1423 - val_loss: 0.1374\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.1424 - val_loss: 0.1356\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 17ms/step - loss: 0.1417 - val_loss: 0.1352\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 0.1423 - val_loss: 0.1344\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.1414 - val_loss: 0.1341\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.1412 - val_loss: 0.1360\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.1408 - val_loss: 0.1344\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 0.1415 - val_loss: 0.1344\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 0.1413 - val_loss: 0.1352\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.1410 - val_loss: 0.1344\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.1410 - val_loss: 0.1353\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.1414 - val_loss: 0.1353\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.1414 - val_loss: 0.1357\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.1415 - val_loss: 0.1341\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.1413 - val_loss: 0.1338\n",
      "Epoch 43/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.1414 - val_loss: 0.1348\n",
      "Epoch 44/100\n",
      "20/20 [==============================] - 0s 17ms/step - loss: 0.1407 - val_loss: 0.1341\n",
      "Epoch 45/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.1402 - val_loss: 0.1353\n",
      "Epoch 46/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.1416 - val_loss: 0.1361\n",
      "Epoch 47/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.1409 - val_loss: 0.1346\n",
      "Epoch 48/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.1410 - val_loss: 0.1358\n",
      "Epoch 49/100\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 0.1405 - val_loss: 0.1339\n",
      "Epoch 50/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.1406 - val_loss: 0.1340\n",
      "Epoch 51/100\n",
      "20/20 [==============================] - 0s 18ms/step - loss: 0.1399 - val_loss: 0.1356\n",
      "Epoch 52/100\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 0.1403 - val_loss: 0.1350\n",
      "Epoch 53/100\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 0.1408 - val_loss: 0.1349\n",
      "Epoch 54/100\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 0.1408 - val_loss: 0.1389\n",
      "Epoch 55/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.1409 - val_loss: 0.1348\n",
      "Epoch 56/100\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 0.1404 - val_loss: 0.1349\n",
      "Epoch 57/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.1405 - val_loss: 0.1361\n",
      "Epoch 58/100\n",
      "20/20 [==============================] - 0s 18ms/step - loss: 0.1406 - val_loss: 0.1337\n",
      "Epoch 59/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.1404 - val_loss: 0.1360\n",
      "Epoch 60/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.1412 - val_loss: 0.1356\n",
      "Epoch 61/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.1401 - val_loss: 0.1339\n",
      "Epoch 62/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.1399 - val_loss: 0.1343\n",
      "Epoch 63/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.1400 - val_loss: 0.1341\n",
      "Epoch 64/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.1406 - val_loss: 0.1341\n",
      "Epoch 65/100\n",
      "20/20 [==============================] - 0s 18ms/step - loss: 0.1408 - val_loss: 0.1355\n",
      "Epoch 66/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.1398 - val_loss: 0.1355\n",
      "Epoch 67/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.1403 - val_loss: 0.1370\n",
      "Epoch 68/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.1404 - val_loss: 0.1345\n",
      "Epoch 69/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.1402 - val_loss: 0.1343\n",
      "Epoch 70/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.1403 - val_loss: 0.1365\n",
      "Epoch 71/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.1402 - val_loss: 0.1363\n",
      "Epoch 72/100\n",
      "20/20 [==============================] - 0s 17ms/step - loss: 0.1405 - val_loss: 0.1348\n",
      "Epoch 73/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.1406 - val_loss: 0.1361\n",
      "Epoch 74/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.1409 - val_loss: 0.1351\n",
      "Epoch 75/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.1404 - val_loss: 0.1347\n",
      "Epoch 76/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.1406 - val_loss: 0.1366\n",
      "Epoch 77/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.1408 - val_loss: 0.1347\n",
      "Epoch 78/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.1407 - val_loss: 0.1375\n",
      "Epoch 79/100\n",
      "20/20 [==============================] - 0s 17ms/step - loss: 0.1406 - val_loss: 0.1358\n",
      "Epoch 80/100\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 0.1403 - val_loss: 0.1341\n",
      "Epoch 81/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.1397 - val_loss: 0.1363\n",
      "Epoch 82/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.1401 - val_loss: 0.1340\n",
      "Epoch 83/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.1406 - val_loss: 0.1346\n",
      "Epoch 84/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.1408 - val_loss: 0.1368\n",
      "Epoch 85/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.1409 - val_loss: 0.1368\n",
      "Epoch 86/100\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.1413 - val_loss: 0.1350\n",
      "Epoch 87/100\n",
      "20/20 [==============================] - 0s 17ms/step - loss: 0.1398 - val_loss: 0.1338\n",
      "Epoch 88/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.1405 - val_loss: 0.1337\n",
      "Epoch 89/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.1406 - val_loss: 0.1368\n",
      "Epoch 90/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.1401 - val_loss: 0.1366\n",
      "Epoch 91/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.1400 - val_loss: 0.1345\n",
      "Epoch 92/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.1403 - val_loss: 0.1348\n",
      "Epoch 93/100\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 0.1399 - val_loss: 0.1350\n",
      "Epoch 94/100\n",
      "20/20 [==============================] - 0s 18ms/step - loss: 0.1400 - val_loss: 0.1353\n",
      "Epoch 95/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.1402 - val_loss: 0.1366\n",
      "Epoch 96/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.1413 - val_loss: 0.1353\n",
      "Epoch 97/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.1396 - val_loss: 0.1339\n",
      "Epoch 98/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.1393 - val_loss: 0.1358\n",
      "Epoch 99/100\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 0.1397 - val_loss: 0.1337\n",
      "Epoch 100/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.1404 - val_loss: 0.1343\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f622032e280>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=100, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bd3cd223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 33ms/step - loss: 0.1316\n",
      "Test loss: 0.13160699605941772\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss = model.evaluate(X_test, y_test)\n",
    "print(f\"Test loss: {loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13647fc9",
   "metadata": {},
   "source": [
    "##### Denormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3d8e10fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 2ms/step\n",
      "Mean Absolute Error on Actual Data: 0.02361227775241208\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Grid dimensions based on the dataset\n",
    "grid_size = int(math.ceil(np.sqrt(num_res)))  # Assuming num_residues has been calculated as the nearest perfect square\n",
    "\n",
    "# Predict using the model on normalized test data\n",
    "predicted_normalized = model.predict(X_test)\n",
    "\n",
    "# Denormalize the predicted data\n",
    "predicted = scaler.inverse_transform(predicted_normalized.reshape(-1, 3))\n",
    "predicted = predicted.reshape(-1, grid_size, grid_size, 3)\n",
    "\n",
    "# Denormalize the actual test data\n",
    "actual = scaler.inverse_transform(y_test.reshape(-1, 3))\n",
    "actual = actual.reshape(-1, grid_size, grid_size, 3)\n",
    "\n",
    "# Calculate Mean Squared Error on the denormalized data\n",
    "mae = mean_absolute_error(actual.reshape(-1, 3), predicted.reshape(-1, 3))\n",
    "print(\"Mean Absolute Error on Actual Data:\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7730cc",
   "metadata": {},
   "source": [
    "##### d_i Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "35c0148b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_distance_for_one_atom_over_time(actual, predicted, atom_index, grid_size):\n",
    "    # Determine the row and column in the grid for the atom index\n",
    "    row = atom_index // grid_size\n",
    "    col = atom_index % grid_size\n",
    "\n",
    "    # Extract the coordinates for the specified atom over all time steps\n",
    "    actual_atom_coords = actual[:, row, col, :]\n",
    "    predicted_atom_coords = predicted[:, row, col, :]\n",
    "    \n",
    "    # Calculate and return the Euclidean distances for this atom over all time steps\n",
    "    distances = np.sqrt(np.sum((actual_atom_coords - predicted_atom_coords) ** 2, axis=1))\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277f288f",
   "metadata": {},
   "source": [
    "##### TM-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2519ae35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The TM-score for all atoms across all time steps is: 0.9999781013109255\n"
     ]
    }
   ],
   "source": [
    "# L_target is the total number of atoms in the protein structure.\n",
    "L_target = num_res\n",
    "L_common = num_res\n",
    "grid_size = int(np.ceil(np.sqrt(L_target)))  # Calculate grid size dynamically\n",
    "\n",
    "# Calculate d0, the normalization factor\n",
    "d0 = 1.24 * np.cbrt(L_target - 15) - 1.8\n",
    "\n",
    "# Initialize the TM-score sum\n",
    "tm_score_sum = 0\n",
    "\n",
    "# Iterate over all atoms to calculate the distance and contribute to the TM-score sum\n",
    "for atom_index in range(L_common):\n",
    "    distances = calculate_distance_for_one_atom_over_time(actual, predicted, atom_index, grid_size)\n",
    "    tm_score_sum += np.sum(1 / (1 + (distances / d0) ** 2))\n",
    "\n",
    "# Normalize the TM-score sum by the length of the target protein to get the final TM-score\n",
    "tm_score = tm_score_sum / (L_target * actual.shape[0])\n",
    "\n",
    "print(f\"The TM-score for all atoms across all time steps is: {tm_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6310b066",
   "metadata": {},
   "source": [
    "##### GoogleNet (Inception V1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c75c5e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, AveragePooling2D, Flatten, Dense, BatchNormalization, Concatenate, Dropout, Reshape\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "8fc42214",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(atomic_coordinates, num_res):\n",
    "    scaler = StandardScaler()\n",
    "    positions_normalized = scaler.fit_transform(atomic_coordinates.reshape(-1, atomic_coordinates.shape[-1])).reshape(atomic_coordinates.shape)\n",
    "\n",
    "    grid_size = int(math.ceil(math.sqrt(num_res)))\n",
    "\n",
    "    reshaped_data = np.zeros((positions_normalized.shape[0], grid_size, grid_size, 3))  # Dynamically sized grid\n",
    "\n",
    "    for i in range(positions_normalized.shape[0]):\n",
    "        for j in range(num_res):\n",
    "            row = j // grid_size\n",
    "            col = j % grid_size\n",
    "            reshaped_data[i, row, col, :] = positions_normalized[i, j, :]\n",
    "\n",
    "    X = reshaped_data[:-1]\n",
    "    y = reshaped_data[1:]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    return X_train, X_test, y_train, y_test, scaler, grid_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ac0d5ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inception module\n",
    "def inception_module(x, filters):\n",
    "    f1, f3r, f3, f5r, f5, fp = filters\n",
    "\n",
    "    conv1 = Conv2D(f1, (1, 1), padding='same', activation='relu')(x)\n",
    "\n",
    "    conv3 = Conv2D(f3r, (1, 1), padding='same', activation='relu')(x)\n",
    "    conv3 = Conv2D(f3, (3, 3), padding='same', activation='relu')(conv3)\n",
    "\n",
    "    conv5 = Conv2D(f5r, (1, 1), padding='same', activation='relu')(x)\n",
    "    conv5 = Conv2D(f5, (5, 5), padding='same', activation='relu')(conv5)\n",
    "\n",
    "    pool = MaxPooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
    "    pool = Conv2D(fp, (1, 1), padding='same', activation='relu')(pool)\n",
    "\n",
    "    return Concatenate(axis=-1)([conv1, conv3, conv5, pool])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "6dc8ee50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the GoogleNet (Inception v1) model\n",
    "def build_googlenet_model(grid_size):\n",
    "    input_layer = Input(shape=(grid_size, grid_size, 3))\n",
    "\n",
    "    x = Conv2D(64, (7, 7), strides=(2, 2), padding='same', activation='relu')(input_layer)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv2D(64, (1, 1), padding='same', activation='relu')(x)\n",
    "    x = Conv2D(192, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "\n",
    "    x = inception_module(x, [64, 96, 128, 16, 32, 32])\n",
    "    x = inception_module(x, [128, 128, 192, 32, 96, 64])\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "\n",
    "    x = inception_module(x, [192, 96, 208, 16, 48, 64])\n",
    "    x = inception_module(x, [160, 112, 224, 24, 64, 64])\n",
    "    x = inception_module(x, [128, 128, 256, 24, 64, 64])\n",
    "    x = inception_module(x, [112, 144, 288, 32, 64, 64])\n",
    "    x = inception_module(x, [256, 160, 320, 32, 128, 128])\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "\n",
    "    x = inception_module(x, [256, 160, 320, 32, 128, 128])\n",
    "    x = inception_module(x, [384, 192, 384, 48, 128, 128])\n",
    "\n",
    "    x = AveragePooling2D(pool_size=(grid_size // 16, grid_size // 16), strides=(1, 1))(x)  # Adjusted pooling size\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(grid_size * grid_size * 3)(x)  # Output layer with units to match reshaped data\n",
    "    output_layer = Reshape((grid_size, grid_size, 3))(x)  # Reshape output to match target data shape\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    model.compile(optimizer='adam', loss='mean_absolute_error')\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "490c7e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, scaler, grid_size = preprocess_data(atomic_coordinates, num_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c1f8c7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_googlenet_model(grid_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "31c1e86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, scaler, grid_size = preprocess_data(atomic_coordinates, num_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b4b7732a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_googlenet_model(grid_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "0205b2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_13 (InputLayer)       [(None, 41, 41, 3)]          0         []                            \n",
      "                                                                                                  \n",
      " conv2d_263 (Conv2D)         (None, 21, 21, 64)           9472      ['input_13[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d_71 (MaxPooli  (None, 11, 11, 64)           0         ['conv2d_263[0][0]']          \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " batch_normalization_21 (Ba  (None, 11, 11, 64)           256       ['max_pooling2d_71[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_264 (Conv2D)         (None, 11, 11, 64)           4160      ['batch_normalization_21[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_265 (Conv2D)         (None, 11, 11, 192)          110784    ['conv2d_264[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_22 (Ba  (None, 11, 11, 192)          768       ['conv2d_265[0][0]']          \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " max_pooling2d_72 (MaxPooli  (None, 6, 6, 192)            0         ['batch_normalization_22[0][0]\n",
      " ng2D)                                                              ']                            \n",
      "                                                                                                  \n",
      " conv2d_267 (Conv2D)         (None, 6, 6, 96)             18528     ['max_pooling2d_72[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_269 (Conv2D)         (None, 6, 6, 16)             3088      ['max_pooling2d_72[0][0]']    \n",
      "                                                                                                  \n",
      " max_pooling2d_73 (MaxPooli  (None, 6, 6, 192)            0         ['max_pooling2d_72[0][0]']    \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv2d_266 (Conv2D)         (None, 6, 6, 64)             12352     ['max_pooling2d_72[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_268 (Conv2D)         (None, 6, 6, 128)            110720    ['conv2d_267[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_270 (Conv2D)         (None, 6, 6, 32)             12832     ['conv2d_269[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_271 (Conv2D)         (None, 6, 6, 32)             6176      ['max_pooling2d_73[0][0]']    \n",
      "                                                                                                  \n",
      " concatenate_36 (Concatenat  (None, 6, 6, 256)            0         ['conv2d_266[0][0]',          \n",
      " e)                                                                  'conv2d_268[0][0]',          \n",
      "                                                                     'conv2d_270[0][0]',          \n",
      "                                                                     'conv2d_271[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_273 (Conv2D)         (None, 6, 6, 128)            32896     ['concatenate_36[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_275 (Conv2D)         (None, 6, 6, 32)             8224      ['concatenate_36[0][0]']      \n",
      "                                                                                                  \n",
      " max_pooling2d_74 (MaxPooli  (None, 6, 6, 256)            0         ['concatenate_36[0][0]']      \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv2d_272 (Conv2D)         (None, 6, 6, 128)            32896     ['concatenate_36[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_274 (Conv2D)         (None, 6, 6, 192)            221376    ['conv2d_273[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_276 (Conv2D)         (None, 6, 6, 96)             76896     ['conv2d_275[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_277 (Conv2D)         (None, 6, 6, 64)             16448     ['max_pooling2d_74[0][0]']    \n",
      "                                                                                                  \n",
      " concatenate_37 (Concatenat  (None, 6, 6, 480)            0         ['conv2d_272[0][0]',          \n",
      " e)                                                                  'conv2d_274[0][0]',          \n",
      "                                                                     'conv2d_276[0][0]',          \n",
      "                                                                     'conv2d_277[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling2d_75 (MaxPooli  (None, 3, 3, 480)            0         ['concatenate_37[0][0]']      \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv2d_279 (Conv2D)         (None, 3, 3, 96)             46176     ['max_pooling2d_75[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_281 (Conv2D)         (None, 3, 3, 16)             7696      ['max_pooling2d_75[0][0]']    \n",
      "                                                                                                  \n",
      " max_pooling2d_76 (MaxPooli  (None, 3, 3, 480)            0         ['max_pooling2d_75[0][0]']    \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv2d_278 (Conv2D)         (None, 3, 3, 192)            92352     ['max_pooling2d_75[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_280 (Conv2D)         (None, 3, 3, 208)            179920    ['conv2d_279[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_282 (Conv2D)         (None, 3, 3, 48)             19248     ['conv2d_281[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_283 (Conv2D)         (None, 3, 3, 64)             30784     ['max_pooling2d_76[0][0]']    \n",
      "                                                                                                  \n",
      " concatenate_38 (Concatenat  (None, 3, 3, 512)            0         ['conv2d_278[0][0]',          \n",
      " e)                                                                  'conv2d_280[0][0]',          \n",
      "                                                                     'conv2d_282[0][0]',          \n",
      "                                                                     'conv2d_283[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_285 (Conv2D)         (None, 3, 3, 112)            57456     ['concatenate_38[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_287 (Conv2D)         (None, 3, 3, 24)             12312     ['concatenate_38[0][0]']      \n",
      "                                                                                                  \n",
      " max_pooling2d_77 (MaxPooli  (None, 3, 3, 512)            0         ['concatenate_38[0][0]']      \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv2d_284 (Conv2D)         (None, 3, 3, 160)            82080     ['concatenate_38[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_286 (Conv2D)         (None, 3, 3, 224)            226016    ['conv2d_285[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_288 (Conv2D)         (None, 3, 3, 64)             38464     ['conv2d_287[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_289 (Conv2D)         (None, 3, 3, 64)             32832     ['max_pooling2d_77[0][0]']    \n",
      "                                                                                                  \n",
      " concatenate_39 (Concatenat  (None, 3, 3, 512)            0         ['conv2d_284[0][0]',          \n",
      " e)                                                                  'conv2d_286[0][0]',          \n",
      "                                                                     'conv2d_288[0][0]',          \n",
      "                                                                     'conv2d_289[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_291 (Conv2D)         (None, 3, 3, 128)            65664     ['concatenate_39[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_293 (Conv2D)         (None, 3, 3, 24)             12312     ['concatenate_39[0][0]']      \n",
      "                                                                                                  \n",
      " max_pooling2d_78 (MaxPooli  (None, 3, 3, 512)            0         ['concatenate_39[0][0]']      \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv2d_290 (Conv2D)         (None, 3, 3, 128)            65664     ['concatenate_39[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_292 (Conv2D)         (None, 3, 3, 256)            295168    ['conv2d_291[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_294 (Conv2D)         (None, 3, 3, 64)             38464     ['conv2d_293[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_295 (Conv2D)         (None, 3, 3, 64)             32832     ['max_pooling2d_78[0][0]']    \n",
      "                                                                                                  \n",
      " concatenate_40 (Concatenat  (None, 3, 3, 512)            0         ['conv2d_290[0][0]',          \n",
      " e)                                                                  'conv2d_292[0][0]',          \n",
      "                                                                     'conv2d_294[0][0]',          \n",
      "                                                                     'conv2d_295[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_297 (Conv2D)         (None, 3, 3, 144)            73872     ['concatenate_40[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_299 (Conv2D)         (None, 3, 3, 32)             16416     ['concatenate_40[0][0]']      \n",
      "                                                                                                  \n",
      " max_pooling2d_79 (MaxPooli  (None, 3, 3, 512)            0         ['concatenate_40[0][0]']      \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv2d_296 (Conv2D)         (None, 3, 3, 112)            57456     ['concatenate_40[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_298 (Conv2D)         (None, 3, 3, 288)            373536    ['conv2d_297[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_300 (Conv2D)         (None, 3, 3, 64)             51264     ['conv2d_299[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_301 (Conv2D)         (None, 3, 3, 64)             32832     ['max_pooling2d_79[0][0]']    \n",
      "                                                                                                  \n",
      " concatenate_41 (Concatenat  (None, 3, 3, 528)            0         ['conv2d_296[0][0]',          \n",
      " e)                                                                  'conv2d_298[0][0]',          \n",
      "                                                                     'conv2d_300[0][0]',          \n",
      "                                                                     'conv2d_301[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_303 (Conv2D)         (None, 3, 3, 160)            84640     ['concatenate_41[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_305 (Conv2D)         (None, 3, 3, 32)             16928     ['concatenate_41[0][0]']      \n",
      "                                                                                                  \n",
      " max_pooling2d_80 (MaxPooli  (None, 3, 3, 528)            0         ['concatenate_41[0][0]']      \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv2d_302 (Conv2D)         (None, 3, 3, 256)            135424    ['concatenate_41[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_304 (Conv2D)         (None, 3, 3, 320)            461120    ['conv2d_303[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_306 (Conv2D)         (None, 3, 3, 128)            102528    ['conv2d_305[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_307 (Conv2D)         (None, 3, 3, 128)            67712     ['max_pooling2d_80[0][0]']    \n",
      "                                                                                                  \n",
      " concatenate_42 (Concatenat  (None, 3, 3, 832)            0         ['conv2d_302[0][0]',          \n",
      " e)                                                                  'conv2d_304[0][0]',          \n",
      "                                                                     'conv2d_306[0][0]',          \n",
      "                                                                     'conv2d_307[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling2d_81 (MaxPooli  (None, 2, 2, 832)            0         ['concatenate_42[0][0]']      \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv2d_309 (Conv2D)         (None, 2, 2, 160)            133280    ['max_pooling2d_81[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_311 (Conv2D)         (None, 2, 2, 32)             26656     ['max_pooling2d_81[0][0]']    \n",
      "                                                                                                  \n",
      " max_pooling2d_82 (MaxPooli  (None, 2, 2, 832)            0         ['max_pooling2d_81[0][0]']    \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv2d_308 (Conv2D)         (None, 2, 2, 256)            213248    ['max_pooling2d_81[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_310 (Conv2D)         (None, 2, 2, 320)            461120    ['conv2d_309[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_312 (Conv2D)         (None, 2, 2, 128)            102528    ['conv2d_311[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_313 (Conv2D)         (None, 2, 2, 128)            106624    ['max_pooling2d_82[0][0]']    \n",
      "                                                                                                  \n",
      " concatenate_43 (Concatenat  (None, 2, 2, 832)            0         ['conv2d_308[0][0]',          \n",
      " e)                                                                  'conv2d_310[0][0]',          \n",
      "                                                                     'conv2d_312[0][0]',          \n",
      "                                                                     'conv2d_313[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_315 (Conv2D)         (None, 2, 2, 192)            159936    ['concatenate_43[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_317 (Conv2D)         (None, 2, 2, 48)             39984     ['concatenate_43[0][0]']      \n",
      "                                                                                                  \n",
      " max_pooling2d_83 (MaxPooli  (None, 2, 2, 832)            0         ['concatenate_43[0][0]']      \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv2d_314 (Conv2D)         (None, 2, 2, 384)            319872    ['concatenate_43[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_316 (Conv2D)         (None, 2, 2, 384)            663936    ['conv2d_315[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_318 (Conv2D)         (None, 2, 2, 128)            153728    ['conv2d_317[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_319 (Conv2D)         (None, 2, 2, 128)            106624    ['max_pooling2d_83[0][0]']    \n",
      "                                                                                                  \n",
      " concatenate_44 (Concatenat  (None, 2, 2, 1024)           0         ['conv2d_314[0][0]',          \n",
      " e)                                                                  'conv2d_316[0][0]',          \n",
      "                                                                     'conv2d_318[0][0]',          \n",
      "                                                                     'conv2d_319[0][0]']          \n",
      "                                                                                                  \n",
      " average_pooling2d_4 (Avera  (None, 1, 1, 1024)           0         ['concatenate_44[0][0]']      \n",
      " gePooling2D)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_16 (Dropout)        (None, 1, 1, 1024)           0         ['average_pooling2d_4[0][0]'] \n",
      "                                                                                                  \n",
      " flatten_8 (Flatten)         (None, 1024)                 0         ['dropout_16[0][0]']          \n",
      "                                                                                                  \n",
      " dense_23 (Dense)            (None, 1024)                 1049600   ['flatten_8[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_17 (Dropout)        (None, 1024)                 0         ['dense_23[0][0]']            \n",
      "                                                                                                  \n",
      " dense_24 (Dense)            (None, 5043)                 5169075   ['dropout_17[0][0]']          \n",
      "                                                                                                  \n",
      " reshape_10 (Reshape)        (None, 41, 41, 3)            0         ['dense_24[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 12193251 (46.51 MB)\n",
      "Trainable params: 12192739 (46.51 MB)\n",
      "Non-trainable params: 512 (2.00 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "0d27392d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-25 23:52:32.189669: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_10/dropout_16/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 15s 45ms/step - loss: 0.4510 - val_loss: 0.6191\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 24ms/step - loss: 0.1980 - val_loss: 0.5376\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 24ms/step - loss: 0.1718 - val_loss: 0.4728\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 23ms/step - loss: 0.1745 - val_loss: 0.4435\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 22ms/step - loss: 0.1695 - val_loss: 0.3116\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 22ms/step - loss: 0.1574 - val_loss: 0.2515\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 24ms/step - loss: 0.1362 - val_loss: 0.2364\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 23ms/step - loss: 0.1034 - val_loss: 0.1868\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 24ms/step - loss: 0.0981 - val_loss: 0.1112\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 24ms/step - loss: 0.0921 - val_loss: 0.0775\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 23ms/step - loss: 0.0874 - val_loss: 0.0706\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 22ms/step - loss: 0.0784 - val_loss: 0.0616\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 22ms/step - loss: 0.0810 - val_loss: 0.0614\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 22ms/step - loss: 0.0780 - val_loss: 0.0557\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 22ms/step - loss: 0.0741 - val_loss: 0.0740\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 25ms/step - loss: 0.0733 - val_loss: 0.0620\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 22ms/step - loss: 0.0702 - val_loss: 0.0479\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 22ms/step - loss: 0.0678 - val_loss: 0.0555\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 25ms/step - loss: 0.0641 - val_loss: 0.0563\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 23ms/step - loss: 0.0657 - val_loss: 0.0521\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 22ms/step - loss: 0.0603 - val_loss: 0.0467\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 22ms/step - loss: 0.0605 - val_loss: 0.0429\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 25ms/step - loss: 0.0569 - val_loss: 0.0397\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 23ms/step - loss: 0.0545 - val_loss: 0.0383\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 22ms/step - loss: 0.0527 - val_loss: 0.0403\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 23ms/step - loss: 0.0555 - val_loss: 0.0445\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 23ms/step - loss: 0.0545 - val_loss: 0.0404\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 25ms/step - loss: 0.0518 - val_loss: 0.0369\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 1s 28ms/step - loss: 0.0516 - val_loss: 0.0350\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 24ms/step - loss: 0.0528 - val_loss: 0.0349\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 23ms/step - loss: 0.0495 - val_loss: 0.0379\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 23ms/step - loss: 0.0481 - val_loss: 0.0350\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 25ms/step - loss: 0.0517 - val_loss: 0.0386\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 23ms/step - loss: 0.0506 - val_loss: 0.0378\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 0s 22ms/step - loss: 0.0485 - val_loss: 0.0353\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 0s 24ms/step - loss: 0.0479 - val_loss: 0.0350\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 0s 22ms/step - loss: 0.0464 - val_loss: 0.0341\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 0s 22ms/step - loss: 0.0471 - val_loss: 0.0354\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 0s 22ms/step - loss: 0.0460 - val_loss: 0.0366\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 0s 23ms/step - loss: 0.0460 - val_loss: 0.0310\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 0s 22ms/step - loss: 0.0459 - val_loss: 0.0358\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 0s 25ms/step - loss: 0.0466 - val_loss: 0.0321\n",
      "Epoch 43/100\n",
      "20/20 [==============================] - 0s 23ms/step - loss: 0.0452 - val_loss: 0.0290\n",
      "Epoch 44/100\n",
      "20/20 [==============================] - 0s 23ms/step - loss: 0.0432 - val_loss: 0.0291\n",
      "Epoch 45/100\n",
      "20/20 [==============================] - 0s 23ms/step - loss: 0.0434 - val_loss: 0.0357\n",
      "Epoch 46/100\n",
      "20/20 [==============================] - 0s 24ms/step - loss: 0.0445 - val_loss: 0.0286\n",
      "Epoch 47/100\n",
      "20/20 [==============================] - 0s 22ms/step - loss: 0.0456 - val_loss: 0.0344\n",
      "Epoch 48/100\n",
      "20/20 [==============================] - 0s 24ms/step - loss: 0.0436 - val_loss: 0.0272\n",
      "Epoch 49/100\n",
      "20/20 [==============================] - 0s 24ms/step - loss: 0.0419 - val_loss: 0.0343\n",
      "Epoch 50/100\n",
      "20/20 [==============================] - 0s 22ms/step - loss: 0.0437 - val_loss: 0.0335\n",
      "Epoch 51/100\n",
      "20/20 [==============================] - 0s 23ms/step - loss: 0.0454 - val_loss: 0.0307\n",
      "Epoch 52/100\n",
      "20/20 [==============================] - 0s 23ms/step - loss: 0.0434 - val_loss: 0.0387\n",
      "Epoch 53/100\n",
      "20/20 [==============================] - 0s 24ms/step - loss: 0.0424 - val_loss: 0.0319\n",
      "Epoch 54/100\n",
      "20/20 [==============================] - 0s 24ms/step - loss: 0.0407 - val_loss: 0.0280\n",
      "Epoch 55/100\n",
      "20/20 [==============================] - 0s 24ms/step - loss: 0.0425 - val_loss: 0.0298\n",
      "Epoch 56/100\n",
      "20/20 [==============================] - 0s 24ms/step - loss: 0.0434 - val_loss: 0.0270\n",
      "Epoch 57/100\n",
      "20/20 [==============================] - 0s 22ms/step - loss: 0.0421 - val_loss: 0.0328\n",
      "Epoch 58/100\n",
      "20/20 [==============================] - 0s 22ms/step - loss: 0.0425 - val_loss: 0.0360\n",
      "Epoch 59/100\n",
      "20/20 [==============================] - 0s 22ms/step - loss: 0.0422 - val_loss: 0.0270\n",
      "Epoch 60/100\n",
      "20/20 [==============================] - 0s 23ms/step - loss: 0.0408 - val_loss: 0.0278\n",
      "Epoch 61/100\n",
      "20/20 [==============================] - 0s 24ms/step - loss: 0.0412 - val_loss: 0.0357\n",
      "Epoch 62/100\n",
      "20/20 [==============================] - 0s 24ms/step - loss: 0.0399 - val_loss: 0.0269\n",
      "Epoch 63/100\n",
      "20/20 [==============================] - 0s 22ms/step - loss: 0.0394 - val_loss: 0.0269\n",
      "Epoch 64/100\n",
      "20/20 [==============================] - 0s 22ms/step - loss: 0.0388 - val_loss: 0.0272\n",
      "Epoch 65/100\n",
      "20/20 [==============================] - 0s 22ms/step - loss: 0.0398 - val_loss: 0.0271\n",
      "Epoch 66/100\n",
      "20/20 [==============================] - 0s 22ms/step - loss: 0.0393 - val_loss: 0.0287\n",
      "Epoch 67/100\n",
      "20/20 [==============================] - 0s 22ms/step - loss: 0.0386 - val_loss: 0.0276\n",
      "Epoch 68/100\n",
      "20/20 [==============================] - 0s 24ms/step - loss: 0.0393 - val_loss: 0.0254\n",
      "Epoch 69/100\n",
      "20/20 [==============================] - 0s 22ms/step - loss: 0.0407 - val_loss: 0.0280\n",
      "Epoch 70/100\n",
      "20/20 [==============================] - 0s 23ms/step - loss: 0.0414 - val_loss: 0.0287\n",
      "Epoch 71/100\n",
      "20/20 [==============================] - 0s 24ms/step - loss: 0.0407 - val_loss: 0.0250\n",
      "Epoch 72/100\n",
      "20/20 [==============================] - 0s 23ms/step - loss: 0.0390 - val_loss: 0.0258\n",
      "Epoch 73/100\n",
      "20/20 [==============================] - 0s 22ms/step - loss: 0.0386 - val_loss: 0.0250\n",
      "Epoch 74/100\n",
      "20/20 [==============================] - 0s 23ms/step - loss: 0.0373 - val_loss: 0.0250\n",
      "Epoch 75/100\n",
      "20/20 [==============================] - 0s 23ms/step - loss: 0.0392 - val_loss: 0.0290\n",
      "Epoch 76/100\n",
      "20/20 [==============================] - 0s 24ms/step - loss: 0.0383 - val_loss: 0.0267\n",
      "Epoch 77/100\n",
      "20/20 [==============================] - 0s 24ms/step - loss: 0.0378 - val_loss: 0.0269\n",
      "Epoch 78/100\n",
      "20/20 [==============================] - 0s 22ms/step - loss: 0.0379 - val_loss: 0.0296\n",
      "Epoch 79/100\n",
      "20/20 [==============================] - 0s 23ms/step - loss: 0.0382 - val_loss: 0.0243\n",
      "Epoch 80/100\n",
      "20/20 [==============================] - 0s 23ms/step - loss: 0.0385 - val_loss: 0.0254\n",
      "Epoch 81/100\n",
      "20/20 [==============================] - 0s 23ms/step - loss: 0.0389 - val_loss: 0.0265\n",
      "Epoch 82/100\n",
      "20/20 [==============================] - 0s 23ms/step - loss: 0.0377 - val_loss: 0.0239\n",
      "Epoch 83/100\n",
      "20/20 [==============================] - 0s 24ms/step - loss: 0.0382 - val_loss: 0.0295\n",
      "Epoch 84/100\n",
      "20/20 [==============================] - 0s 23ms/step - loss: 0.0396 - val_loss: 0.0363\n",
      "Epoch 85/100\n",
      "20/20 [==============================] - 0s 23ms/step - loss: 0.0401 - val_loss: 0.0317\n",
      "Epoch 86/100\n",
      "20/20 [==============================] - 0s 22ms/step - loss: 0.0393 - val_loss: 0.0306\n",
      "Epoch 87/100\n",
      "20/20 [==============================] - 0s 22ms/step - loss: 0.0402 - val_loss: 0.0251\n",
      "Epoch 88/100\n",
      "20/20 [==============================] - 0s 22ms/step - loss: 0.0374 - val_loss: 0.0231\n",
      "Epoch 89/100\n",
      "20/20 [==============================] - 0s 22ms/step - loss: 0.0386 - val_loss: 0.0283\n",
      "Epoch 90/100\n",
      "20/20 [==============================] - 0s 24ms/step - loss: 0.0398 - val_loss: 0.0291\n",
      "Epoch 91/100\n",
      "20/20 [==============================] - 0s 22ms/step - loss: 0.0374 - val_loss: 0.0258\n",
      "Epoch 92/100\n",
      "20/20 [==============================] - 0s 23ms/step - loss: 0.0375 - val_loss: 0.0273\n",
      "Epoch 93/100\n",
      "20/20 [==============================] - 0s 23ms/step - loss: 0.0375 - val_loss: 0.0301\n",
      "Epoch 94/100\n",
      "20/20 [==============================] - 0s 22ms/step - loss: 0.0394 - val_loss: 0.0280\n",
      "Epoch 95/100\n",
      "20/20 [==============================] - 0s 22ms/step - loss: 0.0387 - val_loss: 0.0279\n",
      "Epoch 96/100\n",
      "20/20 [==============================] - 0s 22ms/step - loss: 0.0380 - val_loss: 0.0299\n",
      "Epoch 97/100\n",
      "20/20 [==============================] - 0s 22ms/step - loss: 0.0370 - val_loss: 0.0272\n",
      "Epoch 98/100\n",
      "20/20 [==============================] - 0s 23ms/step - loss: 0.0380 - val_loss: 0.0251\n",
      "Epoch 99/100\n",
      "20/20 [==============================] - 0s 25ms/step - loss: 0.0382 - val_loss: 0.0268\n",
      "Epoch 100/100\n",
      "20/20 [==============================] - 0s 23ms/step - loss: 0.0378 - val_loss: 0.0272\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f6544657640>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=100, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "8d13f04b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0267\n",
      "Test loss: 0.026706688106060028\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss = model.evaluate(X_test, y_test)\n",
    "print(f\"Test loss: {loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6452be84",
   "metadata": {},
   "source": [
    "##### Denormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "d0887b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 4ms/step\n",
      "Mean Absolute Error on Actual Data: 0.005198861590368986\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Grid dimensions based on the dataset\n",
    "grid_size = int(math.ceil(np.sqrt(num_res)))  # Assuming num_residues has been calculated as the nearest perfect square\n",
    "\n",
    "# Predict using the model on normalized test data\n",
    "predicted_normalized = model.predict(X_test)\n",
    "\n",
    "# Denormalize the predicted data\n",
    "predicted = scaler.inverse_transform(predicted_normalized.reshape(-1, 3))\n",
    "predicted = predicted.reshape(-1, grid_size, grid_size, 3)\n",
    "\n",
    "# Denormalize the actual test data\n",
    "actual = scaler.inverse_transform(y_test.reshape(-1, 3))\n",
    "actual = actual.reshape(-1, grid_size, grid_size, 3)\n",
    "\n",
    "# Calculate Mean Squared Error on the denormalized data\n",
    "mae = mean_absolute_error(actual.reshape(-1, 3), predicted.reshape(-1, 3))\n",
    "print(\"Mean Absolute Error on Actual Data:\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1449e416",
   "metadata": {},
   "source": [
    "##### d_i Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "9797eeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_distance_for_one_atom_over_time(actual, predicted, atom_index, grid_size):\n",
    "    # Determine the row and column in the grid for the atom index\n",
    "    row = atom_index // grid_size\n",
    "    col = atom_index % grid_size\n",
    "\n",
    "    # Extract the coordinates for the specified atom over all time steps\n",
    "    actual_atom_coords = actual[:, row, col, :]\n",
    "    predicted_atom_coords = predicted[:, row, col, :]\n",
    "    \n",
    "    # Calculate and return the Euclidean distances for this atom over all time steps\n",
    "    distances = np.sqrt(np.sum((actual_atom_coords - predicted_atom_coords) ** 2, axis=1))\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b25a7f",
   "metadata": {},
   "source": [
    "##### TM_Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "1a0c8f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The TM-score for all atoms across all time steps is: 0.9999991343262455\n"
     ]
    }
   ],
   "source": [
    "# L_target is the total number of atoms in the protein structure.\n",
    "L_target = num_res\n",
    "L_common = num_res\n",
    "grid_size = int(np.ceil(np.sqrt(L_target)))  # Calculate grid size dynamically\n",
    "\n",
    "# Calculate d0, the normalization factor\n",
    "d0 = 1.24 * np.cbrt(L_target - 15) - 1.8\n",
    "\n",
    "# Initialize the TM-score sum\n",
    "tm_score_sum = 0\n",
    "\n",
    "# Iterate over all atoms to calculate the distance and contribute to the TM-score sum\n",
    "for atom_index in range(L_common):\n",
    "    distances = calculate_distance_for_one_atom_over_time(actual, predicted, atom_index, grid_size)\n",
    "    tm_score_sum += np.sum(1 / (1 + (distances / d0) ** 2))\n",
    "\n",
    "# Normalize the TM-score sum by the length of the target protein to get the final TM-score\n",
    "tm_score = tm_score_sum / (L_target * actual.shape[0])\n",
    "\n",
    "print(f\"The TM-score for all atoms across all time steps is: {tm_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fdc9007",
   "metadata": {},
   "source": [
    "##### DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "bb36495b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, Concatenate, AveragePooling2D, GlobalAveragePooling2D, Dense, Reshape\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "927e59f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(atomic_coordinates, num_res):\n",
    "    scaler = StandardScaler()\n",
    "    positions_normalized = scaler.fit_transform(atomic_coordinates.reshape(-1, atomic_coordinates.shape[-1])).reshape(atomic_coordinates.shape)\n",
    "\n",
    "    grid_size = int(math.ceil(math.sqrt(num_res)))\n",
    "\n",
    "    reshaped_data = np.zeros((positions_normalized.shape[0], grid_size, grid_size, 3))  # Dynamically sized grid\n",
    "\n",
    "    for i in range(positions_normalized.shape[0]):\n",
    "        for j in range(num_res):\n",
    "            row = j // grid_size\n",
    "            col = j % grid_size\n",
    "            reshaped_data[i, row, col, :] = positions_normalized[i, j, :]\n",
    "\n",
    "    X = reshaped_data[:-1]\n",
    "    y = reshaped_data[1:]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    return X_train, X_test, y_train, y_test, scaler, grid_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f00422cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dense Block\n",
    "def dense_block(x, blocks, name):\n",
    "    for i in range(blocks):\n",
    "        x = conv_block(x, 32, name=name + '_block' + str(i + 1))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "889f11ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolution Block\n",
    "def conv_block(x, growth_rate, name):\n",
    "    x1 = BatchNormalization(axis=3, epsilon=1.001e-5, name=name + '_bn')(x)\n",
    "    x1 = Activation('relu', name=name + '_relu')(x1)\n",
    "    x1 = Conv2D(4 * growth_rate, 1, use_bias=False, name=name + '_conv1')(x1)\n",
    "    x1 = BatchNormalization(axis=3, epsilon=1.001e-5, name=name + '_bn2')(x1)\n",
    "    x1 = Activation('relu', name=name + '_relu2')(x1)\n",
    "    x1 = Conv2D(growth_rate, 3, padding='same', use_bias=False, name=name + '_conv2')(x1)\n",
    "    x = Concatenate(axis=3, name=name + '_concat')([x, x1])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "83115537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transition Layer\n",
    "def transition_block(x, reduction, name):\n",
    "    x = BatchNormalization(axis=3, epsilon=1.001e-5, name=name + '_bn')(x)\n",
    "    x = Activation('relu', name=name + '_relu')(x)\n",
    "    x = Conv2D(int(tf.keras.backend.int_shape(x)[3] * reduction), 1, use_bias=False, name=name + '_conv')(x)\n",
    "    x = AveragePooling2D(2, strides=2, name=name + '_pool')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2e9a76e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the DenseNet model\n",
    "def build_densenet_model(grid_size):\n",
    "    input_layer = Input(shape=(grid_size, grid_size, 3))\n",
    "\n",
    "    x = Conv2D(64, 7, strides=2, use_bias=False, name='conv1/conv')(input_layer)\n",
    "    x = BatchNormalization(axis=3, epsilon=1.001e-5, name='conv1/bn')(x)\n",
    "    x = Activation('relu', name='conv1/relu')(x)\n",
    "    x = AveragePooling2D(3, strides=2, name='pool1')(x)\n",
    "\n",
    "    x = dense_block(x, 6, name='conv2')\n",
    "    x = transition_block(x, 0.5, name='pool2')\n",
    "    x = dense_block(x, 12, name='conv3')\n",
    "    x = transition_block(x, 0.5, name='pool3')\n",
    "    x = dense_block(x, 24, name='conv4')\n",
    "    x = transition_block(x, 0.5, name='pool4')\n",
    "    x = dense_block(x, 16, name='conv5')\n",
    "\n",
    "    x = GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "    x = Dense(grid_size * grid_size * 3, activation='linear')(x)\n",
    "    output_layer = Reshape((grid_size, grid_size, 3))(x)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    model.compile(optimizer='adam', loss='mean_absolute_error')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "653d2d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, scaler, grid_size = preprocess_data(atomic_coordinates, num_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2aba4b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_densenet_model(grid_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "684292a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_11 (InputLayer)       [(None, 41, 41, 3)]          0         []                            \n",
      "                                                                                                  \n",
      " conv1/conv (Conv2D)         (None, 18, 18, 64)           9408      ['input_11[0][0]']            \n",
      "                                                                                                  \n",
      " conv1/bn (BatchNormalizati  (None, 18, 18, 64)           256       ['conv1/conv[0][0]']          \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv1/relu (Activation)     (None, 18, 18, 64)           0         ['conv1/bn[0][0]']            \n",
      "                                                                                                  \n",
      " pool1 (AveragePooling2D)    (None, 8, 8, 64)             0         ['conv1/relu[0][0]']          \n",
      "                                                                                                  \n",
      " conv2_block1_bn (BatchNorm  (None, 8, 8, 64)             256       ['pool1[0][0]']               \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " conv2_block1_relu (Activat  (None, 8, 8, 64)             0         ['conv2_block1_bn[0][0]']     \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " conv2_block1_conv1 (Conv2D  (None, 8, 8, 128)            8192      ['conv2_block1_relu[0][0]']   \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2_block1_bn2 (BatchNor  (None, 8, 8, 128)            512       ['conv2_block1_conv1[0][0]']  \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " conv2_block1_relu2 (Activa  (None, 8, 8, 128)            0         ['conv2_block1_bn2[0][0]']    \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " conv2_block1_conv2 (Conv2D  (None, 8, 8, 32)             36864     ['conv2_block1_relu2[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2_block1_concat (Conca  (None, 8, 8, 96)             0         ['pool1[0][0]',               \n",
      " tenate)                                                             'conv2_block1_conv2[0][0]']  \n",
      "                                                                                                  \n",
      " conv2_block2_bn (BatchNorm  (None, 8, 8, 96)             384       ['conv2_block1_concat[0][0]'] \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " conv2_block2_relu (Activat  (None, 8, 8, 96)             0         ['conv2_block2_bn[0][0]']     \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " conv2_block2_conv1 (Conv2D  (None, 8, 8, 128)            12288     ['conv2_block2_relu[0][0]']   \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2_block2_bn2 (BatchNor  (None, 8, 8, 128)            512       ['conv2_block2_conv1[0][0]']  \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " conv2_block2_relu2 (Activa  (None, 8, 8, 128)            0         ['conv2_block2_bn2[0][0]']    \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " conv2_block2_conv2 (Conv2D  (None, 8, 8, 32)             36864     ['conv2_block2_relu2[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2_block2_concat (Conca  (None, 8, 8, 128)            0         ['conv2_block1_concat[0][0]', \n",
      " tenate)                                                             'conv2_block2_conv2[0][0]']  \n",
      "                                                                                                  \n",
      " conv2_block3_bn (BatchNorm  (None, 8, 8, 128)            512       ['conv2_block2_concat[0][0]'] \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " conv2_block3_relu (Activat  (None, 8, 8, 128)            0         ['conv2_block3_bn[0][0]']     \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " conv2_block3_conv1 (Conv2D  (None, 8, 8, 128)            16384     ['conv2_block3_relu[0][0]']   \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2_block3_bn2 (BatchNor  (None, 8, 8, 128)            512       ['conv2_block3_conv1[0][0]']  \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " conv2_block3_relu2 (Activa  (None, 8, 8, 128)            0         ['conv2_block3_bn2[0][0]']    \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " conv2_block3_conv2 (Conv2D  (None, 8, 8, 32)             36864     ['conv2_block3_relu2[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2_block3_concat (Conca  (None, 8, 8, 160)            0         ['conv2_block2_concat[0][0]', \n",
      " tenate)                                                             'conv2_block3_conv2[0][0]']  \n",
      "                                                                                                  \n",
      " conv2_block4_bn (BatchNorm  (None, 8, 8, 160)            640       ['conv2_block3_concat[0][0]'] \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " conv2_block4_relu (Activat  (None, 8, 8, 160)            0         ['conv2_block4_bn[0][0]']     \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " conv2_block4_conv1 (Conv2D  (None, 8, 8, 128)            20480     ['conv2_block4_relu[0][0]']   \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2_block4_bn2 (BatchNor  (None, 8, 8, 128)            512       ['conv2_block4_conv1[0][0]']  \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " conv2_block4_relu2 (Activa  (None, 8, 8, 128)            0         ['conv2_block4_bn2[0][0]']    \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " conv2_block4_conv2 (Conv2D  (None, 8, 8, 32)             36864     ['conv2_block4_relu2[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2_block4_concat (Conca  (None, 8, 8, 192)            0         ['conv2_block3_concat[0][0]', \n",
      " tenate)                                                             'conv2_block4_conv2[0][0]']  \n",
      "                                                                                                  \n",
      " conv2_block5_bn (BatchNorm  (None, 8, 8, 192)            768       ['conv2_block4_concat[0][0]'] \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " conv2_block5_relu (Activat  (None, 8, 8, 192)            0         ['conv2_block5_bn[0][0]']     \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " conv2_block5_conv1 (Conv2D  (None, 8, 8, 128)            24576     ['conv2_block5_relu[0][0]']   \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2_block5_bn2 (BatchNor  (None, 8, 8, 128)            512       ['conv2_block5_conv1[0][0]']  \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " conv2_block5_relu2 (Activa  (None, 8, 8, 128)            0         ['conv2_block5_bn2[0][0]']    \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " conv2_block5_conv2 (Conv2D  (None, 8, 8, 32)             36864     ['conv2_block5_relu2[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2_block5_concat (Conca  (None, 8, 8, 224)            0         ['conv2_block4_concat[0][0]', \n",
      " tenate)                                                             'conv2_block5_conv2[0][0]']  \n",
      "                                                                                                  \n",
      " conv2_block6_bn (BatchNorm  (None, 8, 8, 224)            896       ['conv2_block5_concat[0][0]'] \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " conv2_block6_relu (Activat  (None, 8, 8, 224)            0         ['conv2_block6_bn[0][0]']     \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " conv2_block6_conv1 (Conv2D  (None, 8, 8, 128)            28672     ['conv2_block6_relu[0][0]']   \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2_block6_bn2 (BatchNor  (None, 8, 8, 128)            512       ['conv2_block6_conv1[0][0]']  \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " conv2_block6_relu2 (Activa  (None, 8, 8, 128)            0         ['conv2_block6_bn2[0][0]']    \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " conv2_block6_conv2 (Conv2D  (None, 8, 8, 32)             36864     ['conv2_block6_relu2[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2_block6_concat (Conca  (None, 8, 8, 256)            0         ['conv2_block5_concat[0][0]', \n",
      " tenate)                                                             'conv2_block6_conv2[0][0]']  \n",
      "                                                                                                  \n",
      " pool2_bn (BatchNormalizati  (None, 8, 8, 256)            1024      ['conv2_block6_concat[0][0]'] \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " pool2_relu (Activation)     (None, 8, 8, 256)            0         ['pool2_bn[0][0]']            \n",
      "                                                                                                  \n",
      " pool2_conv (Conv2D)         (None, 8, 8, 128)            32768     ['pool2_relu[0][0]']          \n",
      "                                                                                                  \n",
      " pool2_pool (AveragePooling  (None, 4, 4, 128)            0         ['pool2_conv[0][0]']          \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block1_bn (BatchNorm  (None, 4, 4, 128)            512       ['pool2_pool[0][0]']          \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " conv3_block1_relu (Activat  (None, 4, 4, 128)            0         ['conv3_block1_bn[0][0]']     \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " conv3_block1_conv1 (Conv2D  (None, 4, 4, 128)            16384     ['conv3_block1_relu[0][0]']   \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv3_block1_bn2 (BatchNor  (None, 4, 4, 128)            512       ['conv3_block1_conv1[0][0]']  \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " conv3_block1_relu2 (Activa  (None, 4, 4, 128)            0         ['conv3_block1_bn2[0][0]']    \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " conv3_block1_conv2 (Conv2D  (None, 4, 4, 32)             36864     ['conv3_block1_relu2[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv3_block1_concat (Conca  (None, 4, 4, 160)            0         ['pool2_pool[0][0]',          \n",
      " tenate)                                                             'conv3_block1_conv2[0][0]']  \n",
      "                                                                                                  \n",
      " conv3_block2_bn (BatchNorm  (None, 4, 4, 160)            640       ['conv3_block1_concat[0][0]'] \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " conv3_block2_relu (Activat  (None, 4, 4, 160)            0         ['conv3_block2_bn[0][0]']     \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " conv3_block2_conv1 (Conv2D  (None, 4, 4, 128)            20480     ['conv3_block2_relu[0][0]']   \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv3_block2_bn2 (BatchNor  (None, 4, 4, 128)            512       ['conv3_block2_conv1[0][0]']  \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " conv3_block2_relu2 (Activa  (None, 4, 4, 128)            0         ['conv3_block2_bn2[0][0]']    \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " conv3_block2_conv2 (Conv2D  (None, 4, 4, 32)             36864     ['conv3_block2_relu2[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv3_block2_concat (Conca  (None, 4, 4, 192)            0         ['conv3_block1_concat[0][0]', \n",
      " tenate)                                                             'conv3_block2_conv2[0][0]']  \n",
      "                                                                                                  \n",
      " conv3_block3_bn (BatchNorm  (None, 4, 4, 192)            768       ['conv3_block2_concat[0][0]'] \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " conv3_block3_relu (Activat  (None, 4, 4, 192)            0         ['conv3_block3_bn[0][0]']     \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " conv3_block3_conv1 (Conv2D  (None, 4, 4, 128)            24576     ['conv3_block3_relu[0][0]']   \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv3_block3_bn2 (BatchNor  (None, 4, 4, 128)            512       ['conv3_block3_conv1[0][0]']  \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " conv3_block3_relu2 (Activa  (None, 4, 4, 128)            0         ['conv3_block3_bn2[0][0]']    \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " conv3_block3_conv2 (Conv2D  (None, 4, 4, 32)             36864     ['conv3_block3_relu2[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv3_block3_concat (Conca  (None, 4, 4, 224)            0         ['conv3_block2_concat[0][0]', \n",
      " tenate)                                                             'conv3_block3_conv2[0][0]']  \n",
      "                                                                                                  \n",
      " conv3_block4_bn (BatchNorm  (None, 4, 4, 224)            896       ['conv3_block3_concat[0][0]'] \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " conv3_block4_relu (Activat  (None, 4, 4, 224)            0         ['conv3_block4_bn[0][0]']     \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " conv3_block4_conv1 (Conv2D  (None, 4, 4, 128)            28672     ['conv3_block4_relu[0][0]']   \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv3_block4_bn2 (BatchNor  (None, 4, 4, 128)            512       ['conv3_block4_conv1[0][0]']  \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " conv3_block4_relu2 (Activa  (None, 4, 4, 128)            0         ['conv3_block4_bn2[0][0]']    \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " conv3_block4_conv2 (Conv2D  (None, 4, 4, 32)             36864     ['conv3_block4_relu2[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv3_block4_concat (Conca  (None, 4, 4, 256)            0         ['conv3_block3_concat[0][0]', \n",
      " tenate)                                                             'conv3_block4_conv2[0][0]']  \n",
      "                                                                                                  \n",
      " conv3_block5_bn (BatchNorm  (None, 4, 4, 256)            1024      ['conv3_block4_concat[0][0]'] \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " conv3_block5_relu (Activat  (None, 4, 4, 256)            0         ['conv3_block5_bn[0][0]']     \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " conv3_block5_conv1 (Conv2D  (None, 4, 4, 128)            32768     ['conv3_block5_relu[0][0]']   \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv3_block5_bn2 (BatchNor  (None, 4, 4, 128)            512       ['conv3_block5_conv1[0][0]']  \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " conv3_block5_relu2 (Activa  (None, 4, 4, 128)            0         ['conv3_block5_bn2[0][0]']    \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " conv3_block5_conv2 (Conv2D  (None, 4, 4, 32)             36864     ['conv3_block5_relu2[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv3_block5_concat (Conca  (None, 4, 4, 288)            0         ['conv3_block4_concat[0][0]', \n",
      " tenate)                                                             'conv3_block5_conv2[0][0]']  \n",
      "                                                                                                  \n",
      " conv3_block6_bn (BatchNorm  (None, 4, 4, 288)            1152      ['conv3_block5_concat[0][0]'] \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " conv3_block6_relu (Activat  (None, 4, 4, 288)            0         ['conv3_block6_bn[0][0]']     \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " conv3_block6_conv1 (Conv2D  (None, 4, 4, 128)            36864     ['conv3_block6_relu[0][0]']   \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv3_block6_bn2 (BatchNor  (None, 4, 4, 128)            512       ['conv3_block6_conv1[0][0]']  \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " conv3_block6_relu2 (Activa  (None, 4, 4, 128)            0         ['conv3_block6_bn2[0][0]']    \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " conv3_block6_conv2 (Conv2D  (None, 4, 4, 32)             36864     ['conv3_block6_relu2[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv3_block6_concat (Conca  (None, 4, 4, 320)            0         ['conv3_block5_concat[0][0]', \n",
      " tenate)                                                             'conv3_block6_conv2[0][0]']  \n",
      "                                                                                                  \n",
      " conv3_block7_bn (BatchNorm  (None, 4, 4, 320)            1280      ['conv3_block6_concat[0][0]'] \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " conv3_block7_relu (Activat  (None, 4, 4, 320)            0         ['conv3_block7_bn[0][0]']     \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " conv3_block7_conv1 (Conv2D  (None, 4, 4, 128)            40960     ['conv3_block7_relu[0][0]']   \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv3_block7_bn2 (BatchNor  (None, 4, 4, 128)            512       ['conv3_block7_conv1[0][0]']  \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " conv3_block7_relu2 (Activa  (None, 4, 4, 128)            0         ['conv3_block7_bn2[0][0]']    \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " conv3_block7_conv2 (Conv2D  (None, 4, 4, 32)             36864     ['conv3_block7_relu2[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv3_block7_concat (Conca  (None, 4, 4, 352)            0         ['conv3_block6_concat[0][0]', \n",
      " tenate)                                                             'conv3_block7_conv2[0][0]']  \n",
      "                                                                                                  \n",
      " conv3_block8_bn (BatchNorm  (None, 4, 4, 352)            1408      ['conv3_block7_concat[0][0]'] \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " conv3_block8_relu (Activat  (None, 4, 4, 352)            0         ['conv3_block8_bn[0][0]']     \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " conv3_block8_conv1 (Conv2D  (None, 4, 4, 128)            45056     ['conv3_block8_relu[0][0]']   \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv3_block8_bn2 (BatchNor  (None, 4, 4, 128)            512       ['conv3_block8_conv1[0][0]']  \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " conv3_block8_relu2 (Activa  (None, 4, 4, 128)            0         ['conv3_block8_bn2[0][0]']    \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " conv3_block8_conv2 (Conv2D  (None, 4, 4, 32)             36864     ['conv3_block8_relu2[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv3_block8_concat (Conca  (None, 4, 4, 384)            0         ['conv3_block7_concat[0][0]', \n",
      " tenate)                                                             'conv3_block8_conv2[0][0]']  \n",
      "                                                                                                  \n",
      " conv3_block9_bn (BatchNorm  (None, 4, 4, 384)            1536      ['conv3_block8_concat[0][0]'] \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " conv3_block9_relu (Activat  (None, 4, 4, 384)            0         ['conv3_block9_bn[0][0]']     \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " conv3_block9_conv1 (Conv2D  (None, 4, 4, 128)            49152     ['conv3_block9_relu[0][0]']   \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv3_block9_bn2 (BatchNor  (None, 4, 4, 128)            512       ['conv3_block9_conv1[0][0]']  \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " conv3_block9_relu2 (Activa  (None, 4, 4, 128)            0         ['conv3_block9_bn2[0][0]']    \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " conv3_block9_conv2 (Conv2D  (None, 4, 4, 32)             36864     ['conv3_block9_relu2[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv3_block9_concat (Conca  (None, 4, 4, 416)            0         ['conv3_block8_concat[0][0]', \n",
      " tenate)                                                             'conv3_block9_conv2[0][0]']  \n",
      "                                                                                                  \n",
      " conv3_block10_bn (BatchNor  (None, 4, 4, 416)            1664      ['conv3_block9_concat[0][0]'] \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " conv3_block10_relu (Activa  (None, 4, 4, 416)            0         ['conv3_block10_bn[0][0]']    \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " conv3_block10_conv1 (Conv2  (None, 4, 4, 128)            53248     ['conv3_block10_relu[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block10_bn2 (BatchNo  (None, 4, 4, 128)            512       ['conv3_block10_conv1[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block10_relu2 (Activ  (None, 4, 4, 128)            0         ['conv3_block10_bn2[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block10_conv2 (Conv2  (None, 4, 4, 32)             36864     ['conv3_block10_relu2[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block10_concat (Conc  (None, 4, 4, 448)            0         ['conv3_block9_concat[0][0]', \n",
      " atenate)                                                            'conv3_block10_conv2[0][0]'] \n",
      "                                                                                                  \n",
      " conv3_block11_bn (BatchNor  (None, 4, 4, 448)            1792      ['conv3_block10_concat[0][0]']\n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " conv3_block11_relu (Activa  (None, 4, 4, 448)            0         ['conv3_block11_bn[0][0]']    \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " conv3_block11_conv1 (Conv2  (None, 4, 4, 128)            57344     ['conv3_block11_relu[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block11_bn2 (BatchNo  (None, 4, 4, 128)            512       ['conv3_block11_conv1[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block11_relu2 (Activ  (None, 4, 4, 128)            0         ['conv3_block11_bn2[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block11_conv2 (Conv2  (None, 4, 4, 32)             36864     ['conv3_block11_relu2[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block11_concat (Conc  (None, 4, 4, 480)            0         ['conv3_block10_concat[0][0]',\n",
      " atenate)                                                            'conv3_block11_conv2[0][0]'] \n",
      "                                                                                                  \n",
      " conv3_block12_bn (BatchNor  (None, 4, 4, 480)            1920      ['conv3_block11_concat[0][0]']\n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " conv3_block12_relu (Activa  (None, 4, 4, 480)            0         ['conv3_block12_bn[0][0]']    \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " conv3_block12_conv1 (Conv2  (None, 4, 4, 128)            61440     ['conv3_block12_relu[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block12_bn2 (BatchNo  (None, 4, 4, 128)            512       ['conv3_block12_conv1[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block12_relu2 (Activ  (None, 4, 4, 128)            0         ['conv3_block12_bn2[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block12_conv2 (Conv2  (None, 4, 4, 32)             36864     ['conv3_block12_relu2[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block12_concat (Conc  (None, 4, 4, 512)            0         ['conv3_block11_concat[0][0]',\n",
      " atenate)                                                            'conv3_block12_conv2[0][0]'] \n",
      "                                                                                                  \n",
      " pool3_bn (BatchNormalizati  (None, 4, 4, 512)            2048      ['conv3_block12_concat[0][0]']\n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " pool3_relu (Activation)     (None, 4, 4, 512)            0         ['pool3_bn[0][0]']            \n",
      "                                                                                                  \n",
      " pool3_conv (Conv2D)         (None, 4, 4, 256)            131072    ['pool3_relu[0][0]']          \n",
      "                                                                                                  \n",
      " pool3_pool (AveragePooling  (None, 2, 2, 256)            0         ['pool3_conv[0][0]']          \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block1_bn (BatchNorm  (None, 2, 2, 256)            1024      ['pool3_pool[0][0]']          \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " conv4_block1_relu (Activat  (None, 2, 2, 256)            0         ['conv4_block1_bn[0][0]']     \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block1_conv1 (Conv2D  (None, 2, 2, 128)            32768     ['conv4_block1_relu[0][0]']   \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv4_block1_bn2 (BatchNor  (None, 2, 2, 128)            512       ['conv4_block1_conv1[0][0]']  \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " conv4_block1_relu2 (Activa  (None, 2, 2, 128)            0         ['conv4_block1_bn2[0][0]']    \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " conv4_block1_conv2 (Conv2D  (None, 2, 2, 32)             36864     ['conv4_block1_relu2[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv4_block1_concat (Conca  (None, 2, 2, 288)            0         ['pool3_pool[0][0]',          \n",
      " tenate)                                                             'conv4_block1_conv2[0][0]']  \n",
      "                                                                                                  \n",
      " conv4_block2_bn (BatchNorm  (None, 2, 2, 288)            1152      ['conv4_block1_concat[0][0]'] \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " conv4_block2_relu (Activat  (None, 2, 2, 288)            0         ['conv4_block2_bn[0][0]']     \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block2_conv1 (Conv2D  (None, 2, 2, 128)            36864     ['conv4_block2_relu[0][0]']   \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv4_block2_bn2 (BatchNor  (None, 2, 2, 128)            512       ['conv4_block2_conv1[0][0]']  \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " conv4_block2_relu2 (Activa  (None, 2, 2, 128)            0         ['conv4_block2_bn2[0][0]']    \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " conv4_block2_conv2 (Conv2D  (None, 2, 2, 32)             36864     ['conv4_block2_relu2[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv4_block2_concat (Conca  (None, 2, 2, 320)            0         ['conv4_block1_concat[0][0]', \n",
      " tenate)                                                             'conv4_block2_conv2[0][0]']  \n",
      "                                                                                                  \n",
      " conv4_block3_bn (BatchNorm  (None, 2, 2, 320)            1280      ['conv4_block2_concat[0][0]'] \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " conv4_block3_relu (Activat  (None, 2, 2, 320)            0         ['conv4_block3_bn[0][0]']     \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block3_conv1 (Conv2D  (None, 2, 2, 128)            40960     ['conv4_block3_relu[0][0]']   \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv4_block3_bn2 (BatchNor  (None, 2, 2, 128)            512       ['conv4_block3_conv1[0][0]']  \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " conv4_block3_relu2 (Activa  (None, 2, 2, 128)            0         ['conv4_block3_bn2[0][0]']    \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " conv4_block3_conv2 (Conv2D  (None, 2, 2, 32)             36864     ['conv4_block3_relu2[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv4_block3_concat (Conca  (None, 2, 2, 352)            0         ['conv4_block2_concat[0][0]', \n",
      " tenate)                                                             'conv4_block3_conv2[0][0]']  \n",
      "                                                                                                  \n",
      " conv4_block4_bn (BatchNorm  (None, 2, 2, 352)            1408      ['conv4_block3_concat[0][0]'] \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " conv4_block4_relu (Activat  (None, 2, 2, 352)            0         ['conv4_block4_bn[0][0]']     \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block4_conv1 (Conv2D  (None, 2, 2, 128)            45056     ['conv4_block4_relu[0][0]']   \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv4_block4_bn2 (BatchNor  (None, 2, 2, 128)            512       ['conv4_block4_conv1[0][0]']  \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " conv4_block4_relu2 (Activa  (None, 2, 2, 128)            0         ['conv4_block4_bn2[0][0]']    \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " conv4_block4_conv2 (Conv2D  (None, 2, 2, 32)             36864     ['conv4_block4_relu2[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv4_block4_concat (Conca  (None, 2, 2, 384)            0         ['conv4_block3_concat[0][0]', \n",
      " tenate)                                                             'conv4_block4_conv2[0][0]']  \n",
      "                                                                                                  \n",
      " conv4_block5_bn (BatchNorm  (None, 2, 2, 384)            1536      ['conv4_block4_concat[0][0]'] \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " conv4_block5_relu (Activat  (None, 2, 2, 384)            0         ['conv4_block5_bn[0][0]']     \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block5_conv1 (Conv2D  (None, 2, 2, 128)            49152     ['conv4_block5_relu[0][0]']   \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv4_block5_bn2 (BatchNor  (None, 2, 2, 128)            512       ['conv4_block5_conv1[0][0]']  \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " conv4_block5_relu2 (Activa  (None, 2, 2, 128)            0         ['conv4_block5_bn2[0][0]']    \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " conv4_block5_conv2 (Conv2D  (None, 2, 2, 32)             36864     ['conv4_block5_relu2[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv4_block5_concat (Conca  (None, 2, 2, 416)            0         ['conv4_block4_concat[0][0]', \n",
      " tenate)                                                             'conv4_block5_conv2[0][0]']  \n",
      "                                                                                                  \n",
      " conv4_block6_bn (BatchNorm  (None, 2, 2, 416)            1664      ['conv4_block5_concat[0][0]'] \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " conv4_block6_relu (Activat  (None, 2, 2, 416)            0         ['conv4_block6_bn[0][0]']     \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block6_conv1 (Conv2D  (None, 2, 2, 128)            53248     ['conv4_block6_relu[0][0]']   \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv4_block6_bn2 (BatchNor  (None, 2, 2, 128)            512       ['conv4_block6_conv1[0][0]']  \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " conv4_block6_relu2 (Activa  (None, 2, 2, 128)            0         ['conv4_block6_bn2[0][0]']    \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " conv4_block6_conv2 (Conv2D  (None, 2, 2, 32)             36864     ['conv4_block6_relu2[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv4_block6_concat (Conca  (None, 2, 2, 448)            0         ['conv4_block5_concat[0][0]', \n",
      " tenate)                                                             'conv4_block6_conv2[0][0]']  \n",
      "                                                                                                  \n",
      " conv4_block7_bn (BatchNorm  (None, 2, 2, 448)            1792      ['conv4_block6_concat[0][0]'] \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " conv4_block7_relu (Activat  (None, 2, 2, 448)            0         ['conv4_block7_bn[0][0]']     \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block7_conv1 (Conv2D  (None, 2, 2, 128)            57344     ['conv4_block7_relu[0][0]']   \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv4_block7_bn2 (BatchNor  (None, 2, 2, 128)            512       ['conv4_block7_conv1[0][0]']  \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " conv4_block7_relu2 (Activa  (None, 2, 2, 128)            0         ['conv4_block7_bn2[0][0]']    \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " conv4_block7_conv2 (Conv2D  (None, 2, 2, 32)             36864     ['conv4_block7_relu2[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv4_block7_concat (Conca  (None, 2, 2, 480)            0         ['conv4_block6_concat[0][0]', \n",
      " tenate)                                                             'conv4_block7_conv2[0][0]']  \n",
      "                                                                                                  \n",
      " conv4_block8_bn (BatchNorm  (None, 2, 2, 480)            1920      ['conv4_block7_concat[0][0]'] \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " conv4_block8_relu (Activat  (None, 2, 2, 480)            0         ['conv4_block8_bn[0][0]']     \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block8_conv1 (Conv2D  (None, 2, 2, 128)            61440     ['conv4_block8_relu[0][0]']   \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv4_block8_bn2 (BatchNor  (None, 2, 2, 128)            512       ['conv4_block8_conv1[0][0]']  \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " conv4_block8_relu2 (Activa  (None, 2, 2, 128)            0         ['conv4_block8_bn2[0][0]']    \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " conv4_block8_conv2 (Conv2D  (None, 2, 2, 32)             36864     ['conv4_block8_relu2[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv4_block8_concat (Conca  (None, 2, 2, 512)            0         ['conv4_block7_concat[0][0]', \n",
      " tenate)                                                             'conv4_block8_conv2[0][0]']  \n",
      "                                                                                                  \n",
      " conv4_block9_bn (BatchNorm  (None, 2, 2, 512)            2048      ['conv4_block8_concat[0][0]'] \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " conv4_block9_relu (Activat  (None, 2, 2, 512)            0         ['conv4_block9_bn[0][0]']     \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block9_conv1 (Conv2D  (None, 2, 2, 128)            65536     ['conv4_block9_relu[0][0]']   \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv4_block9_bn2 (BatchNor  (None, 2, 2, 128)            512       ['conv4_block9_conv1[0][0]']  \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " conv4_block9_relu2 (Activa  (None, 2, 2, 128)            0         ['conv4_block9_bn2[0][0]']    \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " conv4_block9_conv2 (Conv2D  (None, 2, 2, 32)             36864     ['conv4_block9_relu2[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv4_block9_concat (Conca  (None, 2, 2, 544)            0         ['conv4_block8_concat[0][0]', \n",
      " tenate)                                                             'conv4_block9_conv2[0][0]']  \n",
      "                                                                                                  \n",
      " conv4_block10_bn (BatchNor  (None, 2, 2, 544)            2176      ['conv4_block9_concat[0][0]'] \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " conv4_block10_relu (Activa  (None, 2, 2, 544)            0         ['conv4_block10_bn[0][0]']    \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " conv4_block10_conv1 (Conv2  (None, 2, 2, 128)            69632     ['conv4_block10_relu[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block10_bn2 (BatchNo  (None, 2, 2, 128)            512       ['conv4_block10_conv1[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block10_relu2 (Activ  (None, 2, 2, 128)            0         ['conv4_block10_bn2[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block10_conv2 (Conv2  (None, 2, 2, 32)             36864     ['conv4_block10_relu2[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block10_concat (Conc  (None, 2, 2, 576)            0         ['conv4_block9_concat[0][0]', \n",
      " atenate)                                                            'conv4_block10_conv2[0][0]'] \n",
      "                                                                                                  \n",
      " conv4_block11_bn (BatchNor  (None, 2, 2, 576)            2304      ['conv4_block10_concat[0][0]']\n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " conv4_block11_relu (Activa  (None, 2, 2, 576)            0         ['conv4_block11_bn[0][0]']    \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " conv4_block11_conv1 (Conv2  (None, 2, 2, 128)            73728     ['conv4_block11_relu[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block11_bn2 (BatchNo  (None, 2, 2, 128)            512       ['conv4_block11_conv1[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block11_relu2 (Activ  (None, 2, 2, 128)            0         ['conv4_block11_bn2[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block11_conv2 (Conv2  (None, 2, 2, 32)             36864     ['conv4_block11_relu2[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block11_concat (Conc  (None, 2, 2, 608)            0         ['conv4_block10_concat[0][0]',\n",
      " atenate)                                                            'conv4_block11_conv2[0][0]'] \n",
      "                                                                                                  \n",
      " conv4_block12_bn (BatchNor  (None, 2, 2, 608)            2432      ['conv4_block11_concat[0][0]']\n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " conv4_block12_relu (Activa  (None, 2, 2, 608)            0         ['conv4_block12_bn[0][0]']    \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " conv4_block12_conv1 (Conv2  (None, 2, 2, 128)            77824     ['conv4_block12_relu[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block12_bn2 (BatchNo  (None, 2, 2, 128)            512       ['conv4_block12_conv1[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block12_relu2 (Activ  (None, 2, 2, 128)            0         ['conv4_block12_bn2[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block12_conv2 (Conv2  (None, 2, 2, 32)             36864     ['conv4_block12_relu2[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block12_concat (Conc  (None, 2, 2, 640)            0         ['conv4_block11_concat[0][0]',\n",
      " atenate)                                                            'conv4_block12_conv2[0][0]'] \n",
      "                                                                                                  \n",
      " conv4_block13_bn (BatchNor  (None, 2, 2, 640)            2560      ['conv4_block12_concat[0][0]']\n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " conv4_block13_relu (Activa  (None, 2, 2, 640)            0         ['conv4_block13_bn[0][0]']    \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " conv4_block13_conv1 (Conv2  (None, 2, 2, 128)            81920     ['conv4_block13_relu[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block13_bn2 (BatchNo  (None, 2, 2, 128)            512       ['conv4_block13_conv1[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block13_relu2 (Activ  (None, 2, 2, 128)            0         ['conv4_block13_bn2[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block13_conv2 (Conv2  (None, 2, 2, 32)             36864     ['conv4_block13_relu2[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block13_concat (Conc  (None, 2, 2, 672)            0         ['conv4_block12_concat[0][0]',\n",
      " atenate)                                                            'conv4_block13_conv2[0][0]'] \n",
      "                                                                                                  \n",
      " conv4_block14_bn (BatchNor  (None, 2, 2, 672)            2688      ['conv4_block13_concat[0][0]']\n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " conv4_block14_relu (Activa  (None, 2, 2, 672)            0         ['conv4_block14_bn[0][0]']    \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " conv4_block14_conv1 (Conv2  (None, 2, 2, 128)            86016     ['conv4_block14_relu[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block14_bn2 (BatchNo  (None, 2, 2, 128)            512       ['conv4_block14_conv1[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block14_relu2 (Activ  (None, 2, 2, 128)            0         ['conv4_block14_bn2[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block14_conv2 (Conv2  (None, 2, 2, 32)             36864     ['conv4_block14_relu2[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block14_concat (Conc  (None, 2, 2, 704)            0         ['conv4_block13_concat[0][0]',\n",
      " atenate)                                                            'conv4_block14_conv2[0][0]'] \n",
      "                                                                                                  \n",
      " conv4_block15_bn (BatchNor  (None, 2, 2, 704)            2816      ['conv4_block14_concat[0][0]']\n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " conv4_block15_relu (Activa  (None, 2, 2, 704)            0         ['conv4_block15_bn[0][0]']    \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " conv4_block15_conv1 (Conv2  (None, 2, 2, 128)            90112     ['conv4_block15_relu[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block15_bn2 (BatchNo  (None, 2, 2, 128)            512       ['conv4_block15_conv1[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block15_relu2 (Activ  (None, 2, 2, 128)            0         ['conv4_block15_bn2[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block15_conv2 (Conv2  (None, 2, 2, 32)             36864     ['conv4_block15_relu2[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block15_concat (Conc  (None, 2, 2, 736)            0         ['conv4_block14_concat[0][0]',\n",
      " atenate)                                                            'conv4_block15_conv2[0][0]'] \n",
      "                                                                                                  \n",
      " conv4_block16_bn (BatchNor  (None, 2, 2, 736)            2944      ['conv4_block15_concat[0][0]']\n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " conv4_block16_relu (Activa  (None, 2, 2, 736)            0         ['conv4_block16_bn[0][0]']    \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " conv4_block16_conv1 (Conv2  (None, 2, 2, 128)            94208     ['conv4_block16_relu[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block16_bn2 (BatchNo  (None, 2, 2, 128)            512       ['conv4_block16_conv1[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block16_relu2 (Activ  (None, 2, 2, 128)            0         ['conv4_block16_bn2[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block16_conv2 (Conv2  (None, 2, 2, 32)             36864     ['conv4_block16_relu2[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block16_concat (Conc  (None, 2, 2, 768)            0         ['conv4_block15_concat[0][0]',\n",
      " atenate)                                                            'conv4_block16_conv2[0][0]'] \n",
      "                                                                                                  \n",
      " conv4_block17_bn (BatchNor  (None, 2, 2, 768)            3072      ['conv4_block16_concat[0][0]']\n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " conv4_block17_relu (Activa  (None, 2, 2, 768)            0         ['conv4_block17_bn[0][0]']    \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " conv4_block17_conv1 (Conv2  (None, 2, 2, 128)            98304     ['conv4_block17_relu[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block17_bn2 (BatchNo  (None, 2, 2, 128)            512       ['conv4_block17_conv1[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block17_relu2 (Activ  (None, 2, 2, 128)            0         ['conv4_block17_bn2[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block17_conv2 (Conv2  (None, 2, 2, 32)             36864     ['conv4_block17_relu2[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block17_concat (Conc  (None, 2, 2, 800)            0         ['conv4_block16_concat[0][0]',\n",
      " atenate)                                                            'conv4_block17_conv2[0][0]'] \n",
      "                                                                                                  \n",
      " conv4_block18_bn (BatchNor  (None, 2, 2, 800)            3200      ['conv4_block17_concat[0][0]']\n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " conv4_block18_relu (Activa  (None, 2, 2, 800)            0         ['conv4_block18_bn[0][0]']    \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " conv4_block18_conv1 (Conv2  (None, 2, 2, 128)            102400    ['conv4_block18_relu[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block18_bn2 (BatchNo  (None, 2, 2, 128)            512       ['conv4_block18_conv1[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block18_relu2 (Activ  (None, 2, 2, 128)            0         ['conv4_block18_bn2[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block18_conv2 (Conv2  (None, 2, 2, 32)             36864     ['conv4_block18_relu2[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block18_concat (Conc  (None, 2, 2, 832)            0         ['conv4_block17_concat[0][0]',\n",
      " atenate)                                                            'conv4_block18_conv2[0][0]'] \n",
      "                                                                                                  \n",
      " conv4_block19_bn (BatchNor  (None, 2, 2, 832)            3328      ['conv4_block18_concat[0][0]']\n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " conv4_block19_relu (Activa  (None, 2, 2, 832)            0         ['conv4_block19_bn[0][0]']    \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " conv4_block19_conv1 (Conv2  (None, 2, 2, 128)            106496    ['conv4_block19_relu[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block19_bn2 (BatchNo  (None, 2, 2, 128)            512       ['conv4_block19_conv1[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block19_relu2 (Activ  (None, 2, 2, 128)            0         ['conv4_block19_bn2[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block19_conv2 (Conv2  (None, 2, 2, 32)             36864     ['conv4_block19_relu2[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block19_concat (Conc  (None, 2, 2, 864)            0         ['conv4_block18_concat[0][0]',\n",
      " atenate)                                                            'conv4_block19_conv2[0][0]'] \n",
      "                                                                                                  \n",
      " conv4_block20_bn (BatchNor  (None, 2, 2, 864)            3456      ['conv4_block19_concat[0][0]']\n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " conv4_block20_relu (Activa  (None, 2, 2, 864)            0         ['conv4_block20_bn[0][0]']    \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " conv4_block20_conv1 (Conv2  (None, 2, 2, 128)            110592    ['conv4_block20_relu[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block20_bn2 (BatchNo  (None, 2, 2, 128)            512       ['conv4_block20_conv1[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block20_relu2 (Activ  (None, 2, 2, 128)            0         ['conv4_block20_bn2[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block20_conv2 (Conv2  (None, 2, 2, 32)             36864     ['conv4_block20_relu2[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block20_concat (Conc  (None, 2, 2, 896)            0         ['conv4_block19_concat[0][0]',\n",
      " atenate)                                                            'conv4_block20_conv2[0][0]'] \n",
      "                                                                                                  \n",
      " conv4_block21_bn (BatchNor  (None, 2, 2, 896)            3584      ['conv4_block20_concat[0][0]']\n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " conv4_block21_relu (Activa  (None, 2, 2, 896)            0         ['conv4_block21_bn[0][0]']    \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " conv4_block21_conv1 (Conv2  (None, 2, 2, 128)            114688    ['conv4_block21_relu[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block21_bn2 (BatchNo  (None, 2, 2, 128)            512       ['conv4_block21_conv1[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block21_relu2 (Activ  (None, 2, 2, 128)            0         ['conv4_block21_bn2[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block21_conv2 (Conv2  (None, 2, 2, 32)             36864     ['conv4_block21_relu2[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block21_concat (Conc  (None, 2, 2, 928)            0         ['conv4_block20_concat[0][0]',\n",
      " atenate)                                                            'conv4_block21_conv2[0][0]'] \n",
      "                                                                                                  \n",
      " conv4_block22_bn (BatchNor  (None, 2, 2, 928)            3712      ['conv4_block21_concat[0][0]']\n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " conv4_block22_relu (Activa  (None, 2, 2, 928)            0         ['conv4_block22_bn[0][0]']    \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " conv4_block22_conv1 (Conv2  (None, 2, 2, 128)            118784    ['conv4_block22_relu[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block22_bn2 (BatchNo  (None, 2, 2, 128)            512       ['conv4_block22_conv1[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block22_relu2 (Activ  (None, 2, 2, 128)            0         ['conv4_block22_bn2[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block22_conv2 (Conv2  (None, 2, 2, 32)             36864     ['conv4_block22_relu2[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block22_concat (Conc  (None, 2, 2, 960)            0         ['conv4_block21_concat[0][0]',\n",
      " atenate)                                                            'conv4_block22_conv2[0][0]'] \n",
      "                                                                                                  \n",
      " conv4_block23_bn (BatchNor  (None, 2, 2, 960)            3840      ['conv4_block22_concat[0][0]']\n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " conv4_block23_relu (Activa  (None, 2, 2, 960)            0         ['conv4_block23_bn[0][0]']    \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " conv4_block23_conv1 (Conv2  (None, 2, 2, 128)            122880    ['conv4_block23_relu[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block23_bn2 (BatchNo  (None, 2, 2, 128)            512       ['conv4_block23_conv1[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block23_relu2 (Activ  (None, 2, 2, 128)            0         ['conv4_block23_bn2[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block23_conv2 (Conv2  (None, 2, 2, 32)             36864     ['conv4_block23_relu2[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block23_concat (Conc  (None, 2, 2, 992)            0         ['conv4_block22_concat[0][0]',\n",
      " atenate)                                                            'conv4_block23_conv2[0][0]'] \n",
      "                                                                                                  \n",
      " conv4_block24_bn (BatchNor  (None, 2, 2, 992)            3968      ['conv4_block23_concat[0][0]']\n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " conv4_block24_relu (Activa  (None, 2, 2, 992)            0         ['conv4_block24_bn[0][0]']    \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " conv4_block24_conv1 (Conv2  (None, 2, 2, 128)            126976    ['conv4_block24_relu[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block24_bn2 (BatchNo  (None, 2, 2, 128)            512       ['conv4_block24_conv1[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block24_relu2 (Activ  (None, 2, 2, 128)            0         ['conv4_block24_bn2[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block24_conv2 (Conv2  (None, 2, 2, 32)             36864     ['conv4_block24_relu2[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block24_concat (Conc  (None, 2, 2, 1024)           0         ['conv4_block23_concat[0][0]',\n",
      " atenate)                                                            'conv4_block24_conv2[0][0]'] \n",
      "                                                                                                  \n",
      " pool4_bn (BatchNormalizati  (None, 2, 2, 1024)           4096      ['conv4_block24_concat[0][0]']\n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " pool4_relu (Activation)     (None, 2, 2, 1024)           0         ['pool4_bn[0][0]']            \n",
      "                                                                                                  \n",
      " pool4_conv (Conv2D)         (None, 2, 2, 512)            524288    ['pool4_relu[0][0]']          \n",
      "                                                                                                  \n",
      " pool4_pool (AveragePooling  (None, 1, 1, 512)            0         ['pool4_conv[0][0]']          \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block1_bn (BatchNorm  (None, 1, 1, 512)            2048      ['pool4_pool[0][0]']          \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " conv5_block1_relu (Activat  (None, 1, 1, 512)            0         ['conv5_block1_bn[0][0]']     \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " conv5_block1_conv1 (Conv2D  (None, 1, 1, 128)            65536     ['conv5_block1_relu[0][0]']   \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv5_block1_bn2 (BatchNor  (None, 1, 1, 128)            512       ['conv5_block1_conv1[0][0]']  \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " conv5_block1_relu2 (Activa  (None, 1, 1, 128)            0         ['conv5_block1_bn2[0][0]']    \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " conv5_block1_conv2 (Conv2D  (None, 1, 1, 32)             36864     ['conv5_block1_relu2[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv5_block1_concat (Conca  (None, 1, 1, 544)            0         ['pool4_pool[0][0]',          \n",
      " tenate)                                                             'conv5_block1_conv2[0][0]']  \n",
      "                                                                                                  \n",
      " conv5_block2_bn (BatchNorm  (None, 1, 1, 544)            2176      ['conv5_block1_concat[0][0]'] \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " conv5_block2_relu (Activat  (None, 1, 1, 544)            0         ['conv5_block2_bn[0][0]']     \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " conv5_block2_conv1 (Conv2D  (None, 1, 1, 128)            69632     ['conv5_block2_relu[0][0]']   \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv5_block2_bn2 (BatchNor  (None, 1, 1, 128)            512       ['conv5_block2_conv1[0][0]']  \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " conv5_block2_relu2 (Activa  (None, 1, 1, 128)            0         ['conv5_block2_bn2[0][0]']    \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " conv5_block2_conv2 (Conv2D  (None, 1, 1, 32)             36864     ['conv5_block2_relu2[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv5_block2_concat (Conca  (None, 1, 1, 576)            0         ['conv5_block1_concat[0][0]', \n",
      " tenate)                                                             'conv5_block2_conv2[0][0]']  \n",
      "                                                                                                  \n",
      " conv5_block3_bn (BatchNorm  (None, 1, 1, 576)            2304      ['conv5_block2_concat[0][0]'] \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " conv5_block3_relu (Activat  (None, 1, 1, 576)            0         ['conv5_block3_bn[0][0]']     \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " conv5_block3_conv1 (Conv2D  (None, 1, 1, 128)            73728     ['conv5_block3_relu[0][0]']   \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv5_block3_bn2 (BatchNor  (None, 1, 1, 128)            512       ['conv5_block3_conv1[0][0]']  \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " conv5_block3_relu2 (Activa  (None, 1, 1, 128)            0         ['conv5_block3_bn2[0][0]']    \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " conv5_block3_conv2 (Conv2D  (None, 1, 1, 32)             36864     ['conv5_block3_relu2[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv5_block3_concat (Conca  (None, 1, 1, 608)            0         ['conv5_block2_concat[0][0]', \n",
      " tenate)                                                             'conv5_block3_conv2[0][0]']  \n",
      "                                                                                                  \n",
      " conv5_block4_bn (BatchNorm  (None, 1, 1, 608)            2432      ['conv5_block3_concat[0][0]'] \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " conv5_block4_relu (Activat  (None, 1, 1, 608)            0         ['conv5_block4_bn[0][0]']     \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " conv5_block4_conv1 (Conv2D  (None, 1, 1, 128)            77824     ['conv5_block4_relu[0][0]']   \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv5_block4_bn2 (BatchNor  (None, 1, 1, 128)            512       ['conv5_block4_conv1[0][0]']  \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " conv5_block4_relu2 (Activa  (None, 1, 1, 128)            0         ['conv5_block4_bn2[0][0]']    \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " conv5_block4_conv2 (Conv2D  (None, 1, 1, 32)             36864     ['conv5_block4_relu2[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv5_block4_concat (Conca  (None, 1, 1, 640)            0         ['conv5_block3_concat[0][0]', \n",
      " tenate)                                                             'conv5_block4_conv2[0][0]']  \n",
      "                                                                                                  \n",
      " conv5_block5_bn (BatchNorm  (None, 1, 1, 640)            2560      ['conv5_block4_concat[0][0]'] \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " conv5_block5_relu (Activat  (None, 1, 1, 640)            0         ['conv5_block5_bn[0][0]']     \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " conv5_block5_conv1 (Conv2D  (None, 1, 1, 128)            81920     ['conv5_block5_relu[0][0]']   \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv5_block5_bn2 (BatchNor  (None, 1, 1, 128)            512       ['conv5_block5_conv1[0][0]']  \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " conv5_block5_relu2 (Activa  (None, 1, 1, 128)            0         ['conv5_block5_bn2[0][0]']    \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " conv5_block5_conv2 (Conv2D  (None, 1, 1, 32)             36864     ['conv5_block5_relu2[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv5_block5_concat (Conca  (None, 1, 1, 672)            0         ['conv5_block4_concat[0][0]', \n",
      " tenate)                                                             'conv5_block5_conv2[0][0]']  \n",
      "                                                                                                  \n",
      " conv5_block6_bn (BatchNorm  (None, 1, 1, 672)            2688      ['conv5_block5_concat[0][0]'] \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " conv5_block6_relu (Activat  (None, 1, 1, 672)            0         ['conv5_block6_bn[0][0]']     \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " conv5_block6_conv1 (Conv2D  (None, 1, 1, 128)            86016     ['conv5_block6_relu[0][0]']   \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv5_block6_bn2 (BatchNor  (None, 1, 1, 128)            512       ['conv5_block6_conv1[0][0]']  \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " conv5_block6_relu2 (Activa  (None, 1, 1, 128)            0         ['conv5_block6_bn2[0][0]']    \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " conv5_block6_conv2 (Conv2D  (None, 1, 1, 32)             36864     ['conv5_block6_relu2[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv5_block6_concat (Conca  (None, 1, 1, 704)            0         ['conv5_block5_concat[0][0]', \n",
      " tenate)                                                             'conv5_block6_conv2[0][0]']  \n",
      "                                                                                                  \n",
      " conv5_block7_bn (BatchNorm  (None, 1, 1, 704)            2816      ['conv5_block6_concat[0][0]'] \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " conv5_block7_relu (Activat  (None, 1, 1, 704)            0         ['conv5_block7_bn[0][0]']     \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " conv5_block7_conv1 (Conv2D  (None, 1, 1, 128)            90112     ['conv5_block7_relu[0][0]']   \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv5_block7_bn2 (BatchNor  (None, 1, 1, 128)            512       ['conv5_block7_conv1[0][0]']  \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " conv5_block7_relu2 (Activa  (None, 1, 1, 128)            0         ['conv5_block7_bn2[0][0]']    \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " conv5_block7_conv2 (Conv2D  (None, 1, 1, 32)             36864     ['conv5_block7_relu2[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv5_block7_concat (Conca  (None, 1, 1, 736)            0         ['conv5_block6_concat[0][0]', \n",
      " tenate)                                                             'conv5_block7_conv2[0][0]']  \n",
      "                                                                                                  \n",
      " conv5_block8_bn (BatchNorm  (None, 1, 1, 736)            2944      ['conv5_block7_concat[0][0]'] \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " conv5_block8_relu (Activat  (None, 1, 1, 736)            0         ['conv5_block8_bn[0][0]']     \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " conv5_block8_conv1 (Conv2D  (None, 1, 1, 128)            94208     ['conv5_block8_relu[0][0]']   \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv5_block8_bn2 (BatchNor  (None, 1, 1, 128)            512       ['conv5_block8_conv1[0][0]']  \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " conv5_block8_relu2 (Activa  (None, 1, 1, 128)            0         ['conv5_block8_bn2[0][0]']    \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " conv5_block8_conv2 (Conv2D  (None, 1, 1, 32)             36864     ['conv5_block8_relu2[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv5_block8_concat (Conca  (None, 1, 1, 768)            0         ['conv5_block7_concat[0][0]', \n",
      " tenate)                                                             'conv5_block8_conv2[0][0]']  \n",
      "                                                                                                  \n",
      " conv5_block9_bn (BatchNorm  (None, 1, 1, 768)            3072      ['conv5_block8_concat[0][0]'] \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " conv5_block9_relu (Activat  (None, 1, 1, 768)            0         ['conv5_block9_bn[0][0]']     \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " conv5_block9_conv1 (Conv2D  (None, 1, 1, 128)            98304     ['conv5_block9_relu[0][0]']   \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv5_block9_bn2 (BatchNor  (None, 1, 1, 128)            512       ['conv5_block9_conv1[0][0]']  \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " conv5_block9_relu2 (Activa  (None, 1, 1, 128)            0         ['conv5_block9_bn2[0][0]']    \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " conv5_block9_conv2 (Conv2D  (None, 1, 1, 32)             36864     ['conv5_block9_relu2[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv5_block9_concat (Conca  (None, 1, 1, 800)            0         ['conv5_block8_concat[0][0]', \n",
      " tenate)                                                             'conv5_block9_conv2[0][0]']  \n",
      "                                                                                                  \n",
      " conv5_block10_bn (BatchNor  (None, 1, 1, 800)            3200      ['conv5_block9_concat[0][0]'] \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " conv5_block10_relu (Activa  (None, 1, 1, 800)            0         ['conv5_block10_bn[0][0]']    \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " conv5_block10_conv1 (Conv2  (None, 1, 1, 128)            102400    ['conv5_block10_relu[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block10_bn2 (BatchNo  (None, 1, 1, 128)            512       ['conv5_block10_conv1[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block10_relu2 (Activ  (None, 1, 1, 128)            0         ['conv5_block10_bn2[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block10_conv2 (Conv2  (None, 1, 1, 32)             36864     ['conv5_block10_relu2[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block10_concat (Conc  (None, 1, 1, 832)            0         ['conv5_block9_concat[0][0]', \n",
      " atenate)                                                            'conv5_block10_conv2[0][0]'] \n",
      "                                                                                                  \n",
      " conv5_block11_bn (BatchNor  (None, 1, 1, 832)            3328      ['conv5_block10_concat[0][0]']\n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " conv5_block11_relu (Activa  (None, 1, 1, 832)            0         ['conv5_block11_bn[0][0]']    \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " conv5_block11_conv1 (Conv2  (None, 1, 1, 128)            106496    ['conv5_block11_relu[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block11_bn2 (BatchNo  (None, 1, 1, 128)            512       ['conv5_block11_conv1[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block11_relu2 (Activ  (None, 1, 1, 128)            0         ['conv5_block11_bn2[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block11_conv2 (Conv2  (None, 1, 1, 32)             36864     ['conv5_block11_relu2[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block11_concat (Conc  (None, 1, 1, 864)            0         ['conv5_block10_concat[0][0]',\n",
      " atenate)                                                            'conv5_block11_conv2[0][0]'] \n",
      "                                                                                                  \n",
      " conv5_block12_bn (BatchNor  (None, 1, 1, 864)            3456      ['conv5_block11_concat[0][0]']\n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " conv5_block12_relu (Activa  (None, 1, 1, 864)            0         ['conv5_block12_bn[0][0]']    \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " conv5_block12_conv1 (Conv2  (None, 1, 1, 128)            110592    ['conv5_block12_relu[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block12_bn2 (BatchNo  (None, 1, 1, 128)            512       ['conv5_block12_conv1[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block12_relu2 (Activ  (None, 1, 1, 128)            0         ['conv5_block12_bn2[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block12_conv2 (Conv2  (None, 1, 1, 32)             36864     ['conv5_block12_relu2[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block12_concat (Conc  (None, 1, 1, 896)            0         ['conv5_block11_concat[0][0]',\n",
      " atenate)                                                            'conv5_block12_conv2[0][0]'] \n",
      "                                                                                                  \n",
      " conv5_block13_bn (BatchNor  (None, 1, 1, 896)            3584      ['conv5_block12_concat[0][0]']\n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " conv5_block13_relu (Activa  (None, 1, 1, 896)            0         ['conv5_block13_bn[0][0]']    \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " conv5_block13_conv1 (Conv2  (None, 1, 1, 128)            114688    ['conv5_block13_relu[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block13_bn2 (BatchNo  (None, 1, 1, 128)            512       ['conv5_block13_conv1[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block13_relu2 (Activ  (None, 1, 1, 128)            0         ['conv5_block13_bn2[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block13_conv2 (Conv2  (None, 1, 1, 32)             36864     ['conv5_block13_relu2[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block13_concat (Conc  (None, 1, 1, 928)            0         ['conv5_block12_concat[0][0]',\n",
      " atenate)                                                            'conv5_block13_conv2[0][0]'] \n",
      "                                                                                                  \n",
      " conv5_block14_bn (BatchNor  (None, 1, 1, 928)            3712      ['conv5_block13_concat[0][0]']\n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " conv5_block14_relu (Activa  (None, 1, 1, 928)            0         ['conv5_block14_bn[0][0]']    \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " conv5_block14_conv1 (Conv2  (None, 1, 1, 128)            118784    ['conv5_block14_relu[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block14_bn2 (BatchNo  (None, 1, 1, 128)            512       ['conv5_block14_conv1[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block14_relu2 (Activ  (None, 1, 1, 128)            0         ['conv5_block14_bn2[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block14_conv2 (Conv2  (None, 1, 1, 32)             36864     ['conv5_block14_relu2[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block14_concat (Conc  (None, 1, 1, 960)            0         ['conv5_block13_concat[0][0]',\n",
      " atenate)                                                            'conv5_block14_conv2[0][0]'] \n",
      "                                                                                                  \n",
      " conv5_block15_bn (BatchNor  (None, 1, 1, 960)            3840      ['conv5_block14_concat[0][0]']\n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " conv5_block15_relu (Activa  (None, 1, 1, 960)            0         ['conv5_block15_bn[0][0]']    \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " conv5_block15_conv1 (Conv2  (None, 1, 1, 128)            122880    ['conv5_block15_relu[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block15_bn2 (BatchNo  (None, 1, 1, 128)            512       ['conv5_block15_conv1[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block15_relu2 (Activ  (None, 1, 1, 128)            0         ['conv5_block15_bn2[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block15_conv2 (Conv2  (None, 1, 1, 32)             36864     ['conv5_block15_relu2[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block15_concat (Conc  (None, 1, 1, 992)            0         ['conv5_block14_concat[0][0]',\n",
      " atenate)                                                            'conv5_block15_conv2[0][0]'] \n",
      "                                                                                                  \n",
      " conv5_block16_bn (BatchNor  (None, 1, 1, 992)            3968      ['conv5_block15_concat[0][0]']\n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " conv5_block16_relu (Activa  (None, 1, 1, 992)            0         ['conv5_block16_bn[0][0]']    \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " conv5_block16_conv1 (Conv2  (None, 1, 1, 128)            126976    ['conv5_block16_relu[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block16_bn2 (BatchNo  (None, 1, 1, 128)            512       ['conv5_block16_conv1[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block16_relu2 (Activ  (None, 1, 1, 128)            0         ['conv5_block16_bn2[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block16_conv2 (Conv2  (None, 1, 1, 32)             36864     ['conv5_block16_relu2[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block16_concat (Conc  (None, 1, 1, 1024)           0         ['conv5_block15_concat[0][0]',\n",
      " atenate)                                                            'conv5_block16_conv2[0][0]'] \n",
      "                                                                                                  \n",
      " avg_pool (GlobalAveragePoo  (None, 1024)                 0         ['conv5_block16_concat[0][0]']\n",
      " ling2D)                                                                                          \n",
      "                                                                                                  \n",
      " dense_20 (Dense)            (None, 5043)                 5169075   ['avg_pool[0][0]']            \n",
      "                                                                                                  \n",
      " reshape_8 (Reshape)         (None, 41, 41, 3)            0         ['dense_20[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 12202483 (46.55 MB)\n",
      "Trainable params: 12120883 (46.24 MB)\n",
      "Non-trainable params: 81600 (318.75 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ad83a12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "20/20 [==============================] - 45s 122ms/step - loss: 0.2547 - val_loss: 0.7081\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 1s 63ms/step - loss: 0.1065 - val_loss: 0.5830\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 1s 60ms/step - loss: 0.0767 - val_loss: 0.4781\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 1s 58ms/step - loss: 0.0747 - val_loss: 0.3719\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 1s 58ms/step - loss: 0.0596 - val_loss: 0.3188\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 1s 57ms/step - loss: 0.0549 - val_loss: 0.2457\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 1s 62ms/step - loss: 0.0670 - val_loss: 0.2197\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 1s 59ms/step - loss: 0.0598 - val_loss: 0.1942\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 1s 58ms/step - loss: 0.0490 - val_loss: 0.1500\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 1s 58ms/step - loss: 0.0636 - val_loss: 0.1422\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 1s 57ms/step - loss: 0.0540 - val_loss: 0.1238\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 1s 57ms/step - loss: 0.0469 - val_loss: 0.1210\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 1s 57ms/step - loss: 0.0521 - val_loss: 0.1197\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 1s 61ms/step - loss: 0.0547 - val_loss: 0.1108\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 1s 59ms/step - loss: 0.0516 - val_loss: 0.1090\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 1s 60ms/step - loss: 0.0474 - val_loss: 0.1025\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 1s 57ms/step - loss: 0.0423 - val_loss: 0.0974\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 1s 58ms/step - loss: 0.0418 - val_loss: 0.1211\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 1s 60ms/step - loss: 0.0405 - val_loss: 0.1024\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 1s 58ms/step - loss: 0.0480 - val_loss: 0.0984\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 1s 58ms/step - loss: 0.0521 - val_loss: 0.1074\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 1s 57ms/step - loss: 0.0520 - val_loss: 0.1092\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 1s 58ms/step - loss: 0.0425 - val_loss: 0.1094\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 1s 57ms/step - loss: 0.0391 - val_loss: 0.0983\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 1s 59ms/step - loss: 0.0395 - val_loss: 0.0999\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 1s 61ms/step - loss: 0.0420 - val_loss: 0.0879\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 1s 58ms/step - loss: 0.0463 - val_loss: 0.0996\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 1s 57ms/step - loss: 0.0420 - val_loss: 0.0978\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 1s 58ms/step - loss: 0.0435 - val_loss: 0.0959\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 1s 58ms/step - loss: 0.0372 - val_loss: 0.1129\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 1s 57ms/step - loss: 0.0359 - val_loss: 0.1165\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 1s 58ms/step - loss: 0.0402 - val_loss: 0.1075\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 1s 61ms/step - loss: 0.0422 - val_loss: 0.1151\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 1s 57ms/step - loss: 0.0375 - val_loss: 0.1075\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 1s 58ms/step - loss: 0.0378 - val_loss: 0.1191\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 1s 58ms/step - loss: 0.0396 - val_loss: 0.0995\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 1s 56ms/step - loss: 0.0345 - val_loss: 0.1132\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 1s 59ms/step - loss: 0.0432 - val_loss: 0.1137\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 1s 58ms/step - loss: 0.0416 - val_loss: 0.1383\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 1s 59ms/step - loss: 0.0396 - val_loss: 0.1033\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 1s 58ms/step - loss: 0.0342 - val_loss: 0.1072\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 1s 58ms/step - loss: 0.0414 - val_loss: 0.1248\n",
      "Epoch 43/100\n",
      "20/20 [==============================] - 1s 58ms/step - loss: 0.0374 - val_loss: 0.1220\n",
      "Epoch 44/100\n",
      "20/20 [==============================] - 1s 57ms/step - loss: 0.0390 - val_loss: 0.1974\n",
      "Epoch 45/100\n",
      "20/20 [==============================] - 1s 61ms/step - loss: 0.0398 - val_loss: 0.1763\n",
      "Epoch 46/100\n",
      "20/20 [==============================] - 1s 58ms/step - loss: 0.0360 - val_loss: 0.1599\n",
      "Epoch 47/100\n",
      "20/20 [==============================] - 1s 60ms/step - loss: 0.0421 - val_loss: 0.1591\n",
      "Epoch 48/100\n",
      "20/20 [==============================] - 1s 60ms/step - loss: 0.0389 - val_loss: 0.2666\n",
      "Epoch 49/100\n",
      "20/20 [==============================] - 1s 58ms/step - loss: 0.0337 - val_loss: 0.1458\n",
      "Epoch 50/100\n",
      "20/20 [==============================] - 1s 57ms/step - loss: 0.0367 - val_loss: 0.1733\n",
      "Epoch 51/100\n",
      "20/20 [==============================] - 2s 79ms/step - loss: 0.0363 - val_loss: 0.1788\n",
      "Epoch 52/100\n",
      "20/20 [==============================] - 1s 58ms/step - loss: 0.0363 - val_loss: 0.1582\n",
      "Epoch 53/100\n",
      "20/20 [==============================] - 1s 63ms/step - loss: 0.0360 - val_loss: 0.1543\n",
      "Epoch 54/100\n",
      "20/20 [==============================] - 1s 64ms/step - loss: 0.0338 - val_loss: 0.1538\n",
      "Epoch 55/100\n",
      "20/20 [==============================] - 1s 63ms/step - loss: 0.0348 - val_loss: 0.1578\n",
      "Epoch 56/100\n",
      "20/20 [==============================] - 1s 59ms/step - loss: 0.0348 - val_loss: 0.2109\n",
      "Epoch 57/100\n",
      "20/20 [==============================] - 1s 58ms/step - loss: 0.0363 - val_loss: 0.1970\n",
      "Epoch 58/100\n",
      "20/20 [==============================] - 1s 57ms/step - loss: 0.0374 - val_loss: 0.1523\n",
      "Epoch 59/100\n",
      "20/20 [==============================] - 1s 58ms/step - loss: 0.0349 - val_loss: 0.1030\n",
      "Epoch 60/100\n",
      "20/20 [==============================] - 1s 61ms/step - loss: 0.0379 - val_loss: 0.1334\n",
      "Epoch 61/100\n",
      "20/20 [==============================] - 1s 57ms/step - loss: 0.0337 - val_loss: 0.2073\n",
      "Epoch 62/100\n",
      "20/20 [==============================] - 1s 57ms/step - loss: 0.0381 - val_loss: 0.1238\n",
      "Epoch 63/100\n",
      "20/20 [==============================] - 1s 58ms/step - loss: 0.0411 - val_loss: 0.1247\n",
      "Epoch 64/100\n",
      "20/20 [==============================] - 1s 58ms/step - loss: 0.0360 - val_loss: 0.1400\n",
      "Epoch 65/100\n",
      "20/20 [==============================] - 1s 57ms/step - loss: 0.0331 - val_loss: 0.2114\n",
      "Epoch 66/100\n",
      "20/20 [==============================] - 1s 58ms/step - loss: 0.0304 - val_loss: 0.1499\n",
      "Epoch 67/100\n",
      "20/20 [==============================] - 1s 61ms/step - loss: 0.0315 - val_loss: 0.1532\n",
      "Epoch 68/100\n",
      "20/20 [==============================] - 1s 59ms/step - loss: 0.0355 - val_loss: 0.1324\n",
      "Epoch 69/100\n",
      "20/20 [==============================] - 1s 58ms/step - loss: 0.0293 - val_loss: 0.1308\n",
      "Epoch 70/100\n",
      "20/20 [==============================] - 1s 58ms/step - loss: 0.0295 - val_loss: 0.1134\n",
      "Epoch 71/100\n",
      "20/20 [==============================] - 1s 57ms/step - loss: 0.0316 - val_loss: 0.1098\n",
      "Epoch 72/100\n",
      "20/20 [==============================] - 1s 58ms/step - loss: 0.0318 - val_loss: 0.1437\n",
      "Epoch 73/100\n",
      "20/20 [==============================] - 1s 58ms/step - loss: 0.0367 - val_loss: 0.1081\n",
      "Epoch 74/100\n",
      "20/20 [==============================] - 1s 59ms/step - loss: 0.0349 - val_loss: 0.1396\n",
      "Epoch 75/100\n",
      "20/20 [==============================] - 1s 59ms/step - loss: 0.0346 - val_loss: 0.1534\n",
      "Epoch 76/100\n",
      "20/20 [==============================] - 1s 59ms/step - loss: 0.0314 - val_loss: 0.1449\n",
      "Epoch 77/100\n",
      "20/20 [==============================] - 1s 61ms/step - loss: 0.0325 - val_loss: 0.1214\n",
      "Epoch 78/100\n",
      "20/20 [==============================] - 1s 58ms/step - loss: 0.0310 - val_loss: 0.1189\n",
      "Epoch 79/100\n",
      "20/20 [==============================] - 1s 61ms/step - loss: 0.0325 - val_loss: 0.1151\n",
      "Epoch 80/100\n",
      "20/20 [==============================] - 1s 57ms/step - loss: 0.0300 - val_loss: 0.1617\n",
      "Epoch 81/100\n",
      "20/20 [==============================] - 1s 58ms/step - loss: 0.0301 - val_loss: 0.1192\n",
      "Epoch 82/100\n",
      "20/20 [==============================] - 1s 60ms/step - loss: 0.0297 - val_loss: 0.1531\n",
      "Epoch 83/100\n",
      "20/20 [==============================] - 1s 57ms/step - loss: 0.0287 - val_loss: 0.1241\n",
      "Epoch 84/100\n",
      "20/20 [==============================] - 1s 58ms/step - loss: 0.0291 - val_loss: 0.1235\n",
      "Epoch 85/100\n",
      "20/20 [==============================] - 1s 57ms/step - loss: 0.0304 - val_loss: 0.1719\n",
      "Epoch 86/100\n",
      "20/20 [==============================] - 1s 66ms/step - loss: 0.0282 - val_loss: 0.1664\n",
      "Epoch 87/100\n",
      "20/20 [==============================] - 1s 61ms/step - loss: 0.0302 - val_loss: 0.1358\n",
      "Epoch 88/100\n",
      "20/20 [==============================] - 1s 58ms/step - loss: 0.0288 - val_loss: 0.1589\n",
      "Epoch 89/100\n",
      "20/20 [==============================] - 1s 63ms/step - loss: 0.0296 - val_loss: 0.1263\n",
      "Epoch 90/100\n",
      "20/20 [==============================] - 1s 60ms/step - loss: 0.0309 - val_loss: 0.1037\n",
      "Epoch 91/100\n",
      "20/20 [==============================] - 1s 63ms/step - loss: 0.0309 - val_loss: 0.1426\n",
      "Epoch 92/100\n",
      "20/20 [==============================] - 1s 63ms/step - loss: 0.0299 - val_loss: 0.1482\n",
      "Epoch 93/100\n",
      "20/20 [==============================] - 1s 61ms/step - loss: 0.0291 - val_loss: 0.1513\n",
      "Epoch 94/100\n",
      "20/20 [==============================] - 1s 62ms/step - loss: 0.0295 - val_loss: 0.1279\n",
      "Epoch 95/100\n",
      "20/20 [==============================] - 1s 59ms/step - loss: 0.0316 - val_loss: 0.1469\n",
      "Epoch 96/100\n",
      "20/20 [==============================] - 1s 58ms/step - loss: 0.0312 - val_loss: 0.1301\n",
      "Epoch 97/100\n",
      "20/20 [==============================] - 1s 58ms/step - loss: 0.0376 - val_loss: 0.2115\n",
      "Epoch 98/100\n",
      "20/20 [==============================] - 1s 58ms/step - loss: 0.0390 - val_loss: 0.2162\n",
      "Epoch 99/100\n",
      "20/20 [==============================] - 1s 58ms/step - loss: 0.0356 - val_loss: 0.1655\n",
      "Epoch 100/100\n",
      "20/20 [==============================] - 1s 58ms/step - loss: 0.0331 - val_loss: 0.1766\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f654da6d040>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=100, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "3feaef36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 10ms/step - loss: 0.1795\n",
      "Test loss: 0.17950527369976044\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss = model.evaluate(X_test, y_test)\n",
    "print(f\"Test loss: {loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b126f0",
   "metadata": {},
   "source": [
    "#### Denormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d7de8e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 2s 8ms/step\n",
      "Mean Absolute Error on Actual Data: 0.035060291518481036\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Grid dimensions based on the dataset\n",
    "grid_size = int(math.ceil(np.sqrt(num_res)))  # Assuming num_residues has been calculated as the nearest perfect square\n",
    "\n",
    "# Predict using the model on normalized test data\n",
    "predicted_normalized = model.predict(X_test)\n",
    "\n",
    "# Denormalize the predicted data\n",
    "predicted = scaler.inverse_transform(predicted_normalized.reshape(-1, 3))\n",
    "predicted = predicted.reshape(-1, grid_size, grid_size, 3)\n",
    "\n",
    "# Denormalize the actual test data\n",
    "actual = scaler.inverse_transform(y_test.reshape(-1, 3))\n",
    "actual = actual.reshape(-1, grid_size, grid_size, 3)\n",
    "\n",
    "# Calculate Mean Squared Error on the denormalized data\n",
    "mae = mean_absolute_error(actual.reshape(-1, 3), predicted.reshape(-1, 3))\n",
    "print(\"Mean Absolute Error on Actual Data:\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89b6e83",
   "metadata": {},
   "source": [
    "##### d_i Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "55d192e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_distance_for_one_atom_over_time(actual, predicted, atom_index, grid_size):\n",
    "    # Determine the row and column in the grid for the atom index\n",
    "    row = atom_index // grid_size\n",
    "    col = atom_index % grid_size\n",
    "\n",
    "    # Extract the coordinates for the specified atom over all time steps\n",
    "    actual_atom_coords = actual[:, row, col, :]\n",
    "    predicted_atom_coords = predicted[:, row, col, :]\n",
    "    \n",
    "    # Calculate and return the Euclidean distances for this atom over all time steps\n",
    "    distances = np.sqrt(np.sum((actual_atom_coords - predicted_atom_coords) ** 2, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c397de36",
   "metadata": {},
   "source": [
    "##### TM-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "bbb8b3b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'NoneType' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[114], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m atom_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(L_common):\n\u001b[1;32m     14\u001b[0m     distances \u001b[38;5;241m=\u001b[39m calculate_distance_for_one_atom_over_time(actual, predicted, atom_index, grid_size)\n\u001b[0;32m---> 15\u001b[0m     tm_score_sum \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m (\u001b[43mdistances\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43md0\u001b[49m) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m))\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Normalize the TM-score sum by the length of the target protein to get the final TM-score\u001b[39;00m\n\u001b[1;32m     18\u001b[0m tm_score \u001b[38;5;241m=\u001b[39m tm_score_sum \u001b[38;5;241m/\u001b[39m (L_target \u001b[38;5;241m*\u001b[39m actual\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'NoneType' and 'float'"
     ]
    }
   ],
   "source": [
    "# L_target is the total number of atoms in the protein structure.\n",
    "L_target = num_res\n",
    "L_common = num_res\n",
    "grid_size = int(np.ceil(np.sqrt(L_target)))  # Calculate grid size dynamically\n",
    "\n",
    "# Calculate d0, the normalization factor\n",
    "d0 = 1.24 * np.cbrt(L_target - 15) - 1.8\n",
    "\n",
    "# Initialize the TM-score sum\n",
    "tm_score_sum = 0\n",
    "\n",
    "# Iterate over all atoms to calculate the distance and contribute to the TM-score sum\n",
    "for atom_index in range(L_common):\n",
    "    distances = calculate_distance_for_one_atom_over_time(actual, predicted, atom_index, grid_size)\n",
    "    tm_score_sum += np.sum(1 / (1 + (distances / d0) ** 2))\n",
    "\n",
    "# Normalize the TM-score sum by the length of the target protein to get the final TM-score\n",
    "tm_score = tm_score_sum / (L_target * actual.shape[0])\n",
    "\n",
    "print(f\"The TM-score for all atoms across all time steps is: {tm_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2b1ce9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
